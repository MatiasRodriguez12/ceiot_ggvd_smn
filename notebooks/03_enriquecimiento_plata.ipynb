{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Enriquecimiento de la capa Plata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be488a-6bf7-4136-929d-7362ff0dca6c",
   "metadata": {},
   "source": [
    "En esta notebook trabajaremos sobre los datos horarios previamente generados y la capa Plata intermedia con el objetivo de **enriquecer y completar la información** antes de su uso para análisis avanzados (clustering, PCA, reglas de asociación, etc.).\n",
    "\n",
    "### Las principales tareas realizadas son:\n",
    "- Detección de fechas y horas con datos faltantes.\n",
    "- Imputación de valores `NaN` basados en el promedio del mismo horario del día anterior y posterior.\n",
    "- Comparación entre el dataset original y el imputado.\n",
    "- Exportación del dataset horario imputado.\n",
    "- Verificación final de la cobertura completa de fechas por estación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573fb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importación de librerías completada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Deshabilitar warnings futuros\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Ajustar el ancho máximo para impresión en consola\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "pd.set_option('display.width', 300)         # Ajustar a un ancho suficiente en consola\n",
    "pd.set_option('display.max_colwidth', None) # Evitar recortes en contenido de celdas\n",
    "\n",
    "print(\"Importación de librerías completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## Configuración de paths y carpetas del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069e436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciación de carpetas del proyecto completada.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "PLATA_DIR = Path(\"../data/plata\")\n",
    "\n",
    "archivo_plata = PLATA_DIR / \"dataset_plata_inicial.csv\"\n",
    "archivo_horario = PLATA_DIR / \"horario_archivo.csv\"\n",
    "\n",
    "print(\"Iniciación de carpetas del proyecto completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## Carga del dataset y verificación de estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset diario cargado correctamente\n",
      "Dataset horario cargado correctamente\n",
      "\n",
      " Dataset diario:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2110 entries, 0 to 2109\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ESTACION              2110 non-null   object        \n",
      " 1   FECHA                 2110 non-null   datetime64[ns]\n",
      " 2   TEMP_MEAN             2110 non-null   float64       \n",
      " 3   TEMP_MIN              2110 non-null   float64       \n",
      " 4   TEMP_MAX              2110 non-null   float64       \n",
      " 5   PNM_MEAN              2110 non-null   float64       \n",
      " 6   PNM_MIN               2110 non-null   float64       \n",
      " 7   PNM_MAX               2110 non-null   float64       \n",
      " 8   HUM_MEAN              2110 non-null   float64       \n",
      " 9   HUM_MIN               2110 non-null   int64         \n",
      " 10  HUM_MAX               2110 non-null   int64         \n",
      " 11  WIND_DIR_MEAN         2110 non-null   float64       \n",
      " 12  WIND_DIR_MIN          2110 non-null   int64         \n",
      " 13  WIND_DIR_MAX          2110 non-null   int64         \n",
      " 14  WIND_SPEED_MEAN       2110 non-null   float64       \n",
      " 15  WIND_SPEED_MIN        2110 non-null   int64         \n",
      " 16  WIND_SPEED_MAX        2110 non-null   int64         \n",
      " 17  TEMP_MEAN_NORM        2110 non-null   float64       \n",
      " 18  PNM_MEAN_NORM         2110 non-null   float64       \n",
      " 19  HUM_MEAN_NORM         2110 non-null   float64       \n",
      " 20  WIND_DIR_MEAN_NORM    2110 non-null   float64       \n",
      " 21  WIND_SPEED_MEAN_NORM  2110 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(6), object(1)\n",
      "memory usage: 362.8+ KB\n",
      "\n",
      "\n",
      "          ESTACION      FECHA  TEMP_MEAN  TEMP_MIN  TEMP_MAX  PNM_MEAN  PNM_MIN  PNM_MAX  HUM_MEAN  HUM_MIN  HUM_MAX  WIND_DIR_MEAN  WIND_DIR_MIN  WIND_DIR_MAX  WIND_SPEED_MEAN  WIND_SPEED_MIN  WIND_SPEED_MAX  TEMP_MEAN_NORM  PNM_MEAN_NORM  HUM_MEAN_NORM  WIND_DIR_MEAN_NORM  WIND_SPEED_MEAN_NORM\n",
      "0  CORRIENTES AERO 2024-06-01       19.2      14.4      25.7    1014.3   1012.8   1016.4      78.3       54       98           66.5            30           990             11.8               4              22        0.481818       0.411243       0.676609            0.164437              0.275510\n",
      "1  CORRIENTES AERO 2024-06-02       21.0      15.6      28.0    1013.1   1011.6   1016.7      76.6       47       94           82.1            20           160             10.7               4              22        0.536364       0.375740       0.649922            0.210824              0.247449\n",
      "2  CORRIENTES AERO 2024-06-03       14.6      10.0      21.4    1023.6   1018.2   1027.1      69.3       41       95          186.7           160           210             22.8               9              35        0.342424       0.686391       0.535322            0.521855              0.556122\n",
      "3  CORRIENTES AERO 2024-06-04       12.3       8.4      16.1    1019.8   1017.1   1022.5      90.5       79       97          155.0            90           230              9.5               6              15        0.272727       0.573964       0.868132            0.427594              0.216837\n",
      "4  CORRIENTES AERO 2024-06-05       19.5      14.0      27.3    1015.9   1013.3   1018.0      83.0       57       99          149.2            10           360              7.4               4              17        0.490909       0.458580       0.750392            0.410348              0.163265\n",
      "\n",
      " Dataset horario:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43002 entries, 0 to 43001\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   FECHA             43002 non-null  object        \n",
      " 1   HORA              43002 non-null  int64         \n",
      " 2   TEMP              43002 non-null  float64       \n",
      " 3   HUM               43002 non-null  int64         \n",
      " 4   PNM               43002 non-null  float64       \n",
      " 5   DD                43002 non-null  int64         \n",
      " 6   FF                43002 non-null  int64         \n",
      " 7   NOMBRE            43002 non-null  object        \n",
      " 8   estacion_archivo  43002 non-null  int64         \n",
      " 9   FECHA_HORA        43002 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(5), object(2)\n",
      "memory usage: 3.3+ MB\n",
      "\n",
      "\n",
      "        FECHA  HORA  TEMP  HUM     PNM   DD  FF     NOMBRE  estacion_archivo          FECHA_HORA\n",
      "0  2024-08-22     6  16.6   98  1007.4  180  11  ITUZAINGO          20240822 2024-08-22 06:00:00\n",
      "1  2024-08-22     9  16.2  100  1008.1  140   9  ITUZAINGO          20240822 2024-08-22 09:00:00\n",
      "2  2024-08-22    10  14.4  100  1010.9  140  17  ITUZAINGO          20240822 2024-08-22 10:00:00\n",
      "3  2024-08-22    11  14.0  100  1012.2  140  15  ITUZAINGO          20240822 2024-08-22 11:00:00\n",
      "4  2024-08-22    12  13.6  100  1012.8  140  17  ITUZAINGO          20240822 2024-08-22 12:00:00\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset diario\n",
    "try:\n",
    "    df_plata = pd.read_csv(archivo_plata, parse_dates=[\"FECHA\"])\n",
    "    print(\"Dataset diario cargado correctamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo diario no fue encontrado\")\n",
    "\n",
    "# Cargar el dataset horario\n",
    "try:\n",
    "    df_horario = pd.read_csv(archivo_horario, parse_dates=[\"FECHA_HORA\"])\n",
    "    print(\"Dataset horario cargado correctamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo horario no fue encontrado\")\n",
    "\n",
    "# Vista preliminar\n",
    "print(\"\\n Dataset diario:\")\n",
    "df_plata.info()\n",
    "print(\"\\n\")\n",
    "print(df_plata.head())\n",
    "\n",
    "print(\"\\n Dataset horario:\")\n",
    "df_horario.info()\n",
    "print(\"\\n\")\n",
    "print(df_horario.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209b877-0cff-4dc7-ba04-d9ed38525d7a",
   "metadata": {},
   "source": [
    "Este paso permite validar la estructura general, tipos de datos y posibles columnas faltantes tanto en el dataset diario como en el horario. Si todo está correcto, avanzaremos con el enriquecimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## Detección y análisis de fechas faltantes\n",
    "\n",
    "Una vez verificada la estructura del dataset diario, procedemos a identificar si existen fechas faltantes en la serie por estación. \n",
    "\n",
    "Esto nos permitirá decidir estrategias para tratar los días sin registros, como imputación o exclusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392108e6-7ec0-42ce-a42f-5f1c440573fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas faltantes exportadas a: ../data/plata/fechas_faltantes.txt\n",
      "                    ESTACION      FECHA\n",
      "725          CORRIENTES AERO 2024-10-24\n",
      "726                ITUZAINGO 2024-10-24\n",
      "727     MERCEDES AERO (CTES) 2024-10-24\n",
      "728       MONTE CASEROS AERO 2024-10-24\n",
      "729  PASO DE LOS LIBRES AERO 2024-10-24\n"
     ]
    }
   ],
   "source": [
    "# Generar el rango completo de fechas esperadas\n",
    "fechas_totales = pd.date_range(start=df_plata['FECHA'].min(), end=df_plata['FECHA'].max(), freq='D')\n",
    "\n",
    "# Obtener todas las combinaciones posibles de fecha y estación\n",
    "estaciones = df_plata['ESTACION'].unique()\n",
    "index_completo = pd.MultiIndex.from_product([fechas_totales, estaciones], names=['FECHA', 'ESTACION'])\n",
    "\n",
    "# Reindexar para insertar NaNs explícitos en las fechas faltantes\n",
    "df_plata = df_plata.set_index(['FECHA', 'ESTACION']).reindex(index_completo).reset_index()\n",
    "\n",
    "# Verificar fechas faltantes (para exportar listado)\n",
    "faltantes = df_plata[df_plata.isnull().any(axis=1)][['ESTACION', 'FECHA']]\n",
    "\n",
    "if not faltantes.empty:\n",
    "    faltantes.to_csv(PLATA_DIR / \"fechas_faltantes.txt\", index=False, sep='\\t')\n",
    "    print(\"Fechas faltantes exportadas a:\", PLATA_DIR / \"fechas_faltantes.txt\")\n",
    "else:\n",
    "    print(\"No se encontraron fechas faltantes\")\n",
    "\n",
    "# Mostrar ejemplo si hay faltantes\n",
    "print(faltantes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b85704-5591-470e-a46e-a43346980116",
   "metadata": {},
   "source": [
    "Esta estrategia asegura que cada estación tenga una fila para cada fecha del rango, incluso si originalmente no había registros ese día. Esto deja los valores faltantes como `NaN`, que luego se tratarán."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c913c6-b13f-416a-8d06-ce3e48fc53dc",
   "metadata": {},
   "source": [
    "## Tratamiento de valores nulos\n",
    "\n",
    "Luego de verificar fechas faltantes, analizamos los valores `NaN` dentro del dataset actual para decidir estrategias de imputación o tratamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f65cc-3a3a-4170-908f-3902830d2b18",
   "metadata": {},
   "source": [
    "### Tratamiento de datos faltantes en el dataset diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4bfbac3-51b4-4b6b-8ceb-920aead48862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos por columna:\n",
      "FECHA                    0\n",
      "ESTACION                 0\n",
      "TEMP_MEAN               20\n",
      "TEMP_MIN                20\n",
      "TEMP_MAX                20\n",
      "PNM_MEAN                20\n",
      "PNM_MIN                 20\n",
      "PNM_MAX                 20\n",
      "HUM_MEAN                20\n",
      "HUM_MIN                 20\n",
      "HUM_MAX                 20\n",
      "WIND_DIR_MEAN           20\n",
      "WIND_DIR_MIN            20\n",
      "WIND_DIR_MAX            20\n",
      "WIND_SPEED_MEAN         20\n",
      "WIND_SPEED_MIN          20\n",
      "WIND_SPEED_MAX          20\n",
      "TEMP_MEAN_NORM          20\n",
      "PNM_MEAN_NORM           20\n",
      "HUM_MEAN_NORM           20\n",
      "WIND_DIR_MEAN_NORM      20\n",
      "WIND_SPEED_MEAN_NORM    20\n",
      "dtype: int64\n",
      "\n",
      "Porcentaje de valores nulos:\n",
      "FECHA                   0.00\n",
      "ESTACION                0.00\n",
      "TEMP_MEAN               0.94\n",
      "TEMP_MIN                0.94\n",
      "TEMP_MAX                0.94\n",
      "PNM_MEAN                0.94\n",
      "PNM_MIN                 0.94\n",
      "PNM_MAX                 0.94\n",
      "HUM_MEAN                0.94\n",
      "HUM_MIN                 0.94\n",
      "HUM_MAX                 0.94\n",
      "WIND_DIR_MEAN           0.94\n",
      "WIND_DIR_MIN            0.94\n",
      "WIND_DIR_MAX            0.94\n",
      "WIND_SPEED_MEAN         0.94\n",
      "WIND_SPEED_MIN          0.94\n",
      "WIND_SPEED_MAX          0.94\n",
      "TEMP_MEAN_NORM          0.94\n",
      "PNM_MEAN_NORM           0.94\n",
      "HUM_MEAN_NORM           0.94\n",
      "WIND_DIR_MEAN_NORM      0.94\n",
      "WIND_SPEED_MEAN_NORM    0.94\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Visualizar cantidad de nulos por columna\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df_plata.isnull().sum())\n",
    "\n",
    "# Calcular porcentaje de nulos por columna\n",
    "porcentaje_nulos = df_plata.isnull().mean() * 100\n",
    "print(\"\\nPorcentaje de valores nulos:\")\n",
    "print(porcentaje_nulos.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8a240-a6f6-4609-b13c-0ea3aea43a1c",
   "metadata": {},
   "source": [
    "Una vez identificadas las columnas afectadas, proponemos distintas estrategias para completar los datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8c214-e0d0-4a2a-b7f6-6905872c9356",
   "metadata": {},
   "source": [
    "### Relleno con forward fill por estación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b407236-2e12-4451-9c17-492b77e80fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de datos tras forward fill:\n",
      "        FECHA         ESTACION  TEMP_MEAN  TEMP_MIN  TEMP_MAX  PNM_MEAN  PNM_MIN  PNM_MAX  HUM_MEAN  HUM_MIN  HUM_MAX  WIND_DIR_MEAN  WIND_DIR_MIN  WIND_DIR_MAX  WIND_SPEED_MEAN  WIND_SPEED_MIN  WIND_SPEED_MAX  TEMP_MEAN_NORM  PNM_MEAN_NORM  HUM_MEAN_NORM  WIND_DIR_MEAN_NORM  WIND_SPEED_MEAN_NORM\n",
      "0  2024-06-01  CORRIENTES AERO       19.2      14.4      25.7    1014.3   1012.8   1016.4      78.3     54.0     98.0           66.5          30.0         990.0             11.8             4.0            22.0        0.481818       0.411243       0.676609            0.164437              0.275510\n",
      "5  2024-06-02  CORRIENTES AERO       21.0      15.6      28.0    1013.1   1011.6   1016.7      76.6     47.0     94.0           82.1          20.0         160.0             10.7             4.0            22.0        0.536364       0.375740       0.649922            0.210824              0.247449\n",
      "10 2024-06-03  CORRIENTES AERO       14.6      10.0      21.4    1023.6   1018.2   1027.1      69.3     41.0     95.0          186.7         160.0         210.0             22.8             9.0            35.0        0.342424       0.686391       0.535322            0.521855              0.556122\n",
      "15 2024-06-04  CORRIENTES AERO       12.3       8.4      16.1    1019.8   1017.1   1022.5      90.5     79.0     97.0          155.0          90.0         230.0              9.5             6.0            15.0        0.272727       0.573964       0.868132            0.427594              0.216837\n",
      "20 2024-06-05  CORRIENTES AERO       19.5      14.0      27.3    1015.9   1013.3   1018.0      83.0     57.0     99.0          149.2          10.0         360.0              7.4             4.0            17.0        0.490909       0.458580       0.750392            0.410348              0.163265\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por estación y fecha para aplicar forward fill correctamente\n",
    "df_plata_ffill = df_plata.sort_values(['ESTACION', 'FECHA']).copy()\n",
    "df_plata_ffill.update(df_plata.groupby('ESTACION').ffill())\n",
    "\n",
    "# Vista previa de ejemplo tras forward fill\n",
    "print(\"\\nEjemplo de datos tras forward fill:\")\n",
    "print(df_plata_ffill.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacaf95f-a649-4971-b4ee-9c042fe1db11",
   "metadata": {},
   "source": [
    "### Imputación con la media de cada estación (solo para columnas numéricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6159b92c-f4f2-4554-8400-2d043628374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos después de imputación con medias:\n",
      "TEMP_MEAN          0\n",
      "PNM_MEAN           0\n",
      "HUM_MEAN           0\n",
      "WIND_SPEED_MEAN    0\n",
      "WIND_DIR_MEAN      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputar con la media por estación\n",
    "columnas_a_imputar = ['TEMP_MEAN', 'PNM_MEAN', 'HUM_MEAN', 'WIND_SPEED_MEAN', 'WIND_DIR_MEAN']\n",
    "\n",
    "for col in columnas_a_imputar:\n",
    "    df_plata_ffill[col] = df_plata_ffill.groupby('ESTACION')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Verificar resultado tras imputación\n",
    "print(\"\\nValores nulos después de imputación con medias:\")\n",
    "print(df_plata_ffill[columnas_a_imputar].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908a838-a9c0-4c8f-b1f5-b6005cfa8706",
   "metadata": {},
   "source": [
    "Estas estrategias permiten garantizar que las variables derivadas a construir se basen en datos consistentes, sin afectar la distribución ni introducir sesgos evidentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e25e56-6de6-47c7-9d84-967dd5acbdd0",
   "metadata": {},
   "source": [
    "### Tratamiento de datos faltantes en el dataset horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbd7603-b5fb-446f-9f57-f12b36817782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diferencia de tamaño (horas originales vs completadas por horario habitual):\n",
      "Original: 43002\n",
      "Completo: 43452\n",
      "\n",
      "Ejemplo de datos horarios con NaN insertados:\n",
      "        NOMBRE          FECHA_HORA FECHA  HORA  TEMP  HUM  PNM  DD  FF  estacion_archivo\n",
      "39   ITUZAINGO 2024-06-03 19:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "124  ITUZAINGO 2024-06-09 20:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "423  ITUZAINGO 2024-07-01 11:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "590  ITUZAINGO 2024-07-13 10:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "716  ITUZAINGO 2024-07-22 10:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n"
     ]
    }
   ],
   "source": [
    "# Detectar horarios reales de cada estación\n",
    "df_horario['HORA'] = df_horario['FECHA_HORA'].dt.hour\n",
    "horarios_por_estacion = df_horario.groupby('NOMBRE')['HORA'].value_counts().unstack(fill_value=0)\n",
    "horarios_mas_frecuentes = horarios_por_estacion.idxmax(axis=1)\n",
    "\n",
    "# Detectar horarios outlier (menos del 5% de los días)\n",
    "outliers_horarios = {}\n",
    "for estacion in horarios_por_estacion.index:\n",
    "    total_dias = df_horario[df_horario['NOMBRE'] == estacion]['FECHA_HORA'].dt.date.nunique()\n",
    "    outliers = horarios_por_estacion.loc[estacion][\n",
    "        horarios_por_estacion.loc[estacion] / total_dias < 0.05\n",
    "    ].index.tolist()\n",
    "    if outliers:\n",
    "        outliers_horarios[estacion] = outliers\n",
    "\n",
    "# Crear index completo por estación y sus horarios típicos\n",
    "df_horario['FECHA'] = df_horario['FECHA_HORA'].dt.floor('D')\n",
    "estaciones_h = df_horario['NOMBRE'].unique()\n",
    "fecha_h_min = df_horario['FECHA'].min()\n",
    "fecha_h_max = df_horario['FECHA'].max()\n",
    "rango_fechas = pd.date_range(start=fecha_h_min, end=fecha_h_max, freq='D')\n",
    "\n",
    "# Crear combinaciones válidas por estación\n",
    "porcentaje_frecuencia = 0.05 # al menos en 5% de los días\n",
    "\n",
    "index_completo_personalizado = []\n",
    "for estacion in estaciones_h:\n",
    "    total_dias_estacion = df_horario[df_horario['NOMBRE'] == estacion]['FECHA'].nunique()\n",
    "    horas_validas = horarios_por_estacion.columns[\n",
    "        (horarios_por_estacion.loc[estacion] / total_dias_estacion) >= porcentaje_frecuencia  \n",
    "    ].tolist()\n",
    "\n",
    "    for fecha in rango_fechas:\n",
    "        for hora in horas_validas:\n",
    "            index_completo_personalizado.append((estacion, pd.Timestamp(fecha + pd.Timedelta(hours=hora))))\n",
    "\n",
    "index_completo_h = pd.MultiIndex.from_tuples(index_completo_personalizado, names=['NOMBRE', 'FECHA_HORA'])\n",
    "\n",
    "# Reindexar para insertar valores faltantes en los horarios esperados únicamente\n",
    "df_horario_completo = df_horario.set_index(['NOMBRE', 'FECHA_HORA']).reindex(index_completo_h).reset_index()\n",
    "\n",
    "# Verificación\n",
    "print(\"\\nDiferencia de tamaño (horas originales vs completadas por horario habitual):\")\n",
    "print(\"Original:\", len(df_horario))\n",
    "print(\"Completo:\", len(df_horario_completo))\n",
    "print(\"\\nEjemplo de datos horarios con NaN insertados:\")\n",
    "print(df_horario_completo[df_horario_completo.isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe64ec-63a1-4df4-99b5-7b3a8f844f5f",
   "metadata": {},
   "source": [
    "### Mostrar horarios outliers detectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efa97cf-8e8b-4e6d-bf2c-5f77410e2855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Registros reales en horarios atípicos:\n",
      " - ITUZAINGO: [0, 1, 2, 3, 4, 5, 7, 8, 22, 23]\n",
      " - MERCEDES AERO (CTES): [0, 1, 2, 3, 4, 5, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "# Visualizar registros reales en horarios atípicos detectados\n",
    "print(\"\\n Registros reales en horarios atípicos:\")\n",
    "for estacion, horas in outliers_horarios.items():\n",
    "    print(f\" - {estacion}: {horas}\")\n",
    "\n",
    "# Registrar los registros reales que ocurren en horarios atípicos\n",
    "df_outliers_registros = []\n",
    "for estacion, horas_outlier in outliers_horarios.items():\n",
    "    registros_outlier = df_horario[\n",
    "        (df_horario['NOMBRE'] == estacion) &\n",
    "        (df_horario['HORA'].isin(horas_outlier))\n",
    "    ]\n",
    "    if not registros_outlier.empty:\n",
    "        df_outliers_registros.append(registros_outlier)\n",
    "\n",
    "# Concatenar y exportar si hay registros\n",
    "if df_outliers_registros:\n",
    "    df_outliers_concat = pd.concat(df_outliers_registros)\n",
    "    archivo_outliers = PLATA_DIR / \"registros_horarios_atipicos.csv\"\n",
    "    df_outliers_concat.to_csv(archivo_outliers, index=False)\n",
    "    print(\"\\n Archivo exportado con registros reales en horarios atípicos:\")\n",
    "    print(archivo_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ab9e1-38b0-422b-8ac8-fabee6b2cc05",
   "metadata": {},
   "source": [
    "## Exportar datasets intermedios (antes de procesar los NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e123bf3d-a7ba-4ed6-b638-889d892267bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos generados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Exportar datasets intermedios (si se desea conservar)\n",
    "df_plata.to_csv(PLATA_DIR / \"dataset_intermedio_horario_con_nan.csv\", index=False)\n",
    "df_plata_ffill.to_csv(PLATA_DIR / \"dataset_intermedio_horario_ffill.csv\", index=False)\n",
    "df_horario_completo.to_csv(PLATA_DIR / \"dataset_intermedio_horario_completo.csv\", index=False)\n",
    "\n",
    "print(\"Archivos generados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387836d4-c0de-457a-b4ff-7db2548ab541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     NOMBRE          FECHA_HORA      FECHA  HORA  TEMP   HUM     PNM     DD    FF  estacion_archivo\n",
      "0                 ITUZAINGO 2024-06-01 06:00:00 2024-06-01   6.0  15.8  87.0  1015.1  360.0  11.0        20240601.0\n",
      "1                 ITUZAINGO 2024-06-01 09:00:00 2024-06-01   9.0  17.8  73.0  1016.0   50.0  15.0        20240601.0\n",
      "2                 ITUZAINGO 2024-06-01 10:00:00 2024-06-01  10.0  18.4  71.0  1016.3   50.0  15.0        20240601.0\n",
      "3                 ITUZAINGO 2024-06-01 11:00:00 2024-06-01  11.0  20.1  67.0  1016.1   50.0  15.0        20240601.0\n",
      "4                 ITUZAINGO 2024-06-01 12:00:00 2024-06-01  12.0  21.4  64.0  1018.1   50.0  17.0        20240601.0\n",
      "...                     ...                 ...        ...   ...   ...   ...     ...    ...   ...               ...\n",
      "43447  MERCEDES AERO (CTES) 2025-07-31 17:00:00 2025-07-31  17.0  23.4  46.0  1010.5   20.0  26.0        20250731.0\n",
      "43448  MERCEDES AERO (CTES) 2025-07-31 18:00:00 2025-07-31  18.0  21.6  54.0  1010.4   20.0  24.0        20250731.0\n",
      "43449  MERCEDES AERO (CTES) 2025-07-31 19:00:00 2025-07-31  19.0  20.5  55.0  1010.7   20.0  22.0        20250731.0\n",
      "43450  MERCEDES AERO (CTES) 2025-07-31 20:00:00 2025-07-31  20.0  19.5  60.0  1011.3   20.0  19.0        20250731.0\n",
      "43451  MERCEDES AERO (CTES) 2025-07-31 21:00:00 2025-07-31  21.0  18.9  67.0  1011.4   20.0  20.0        20250731.0\n",
      "\n",
      "[43452 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_horario_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b914b3-5333-417a-b3d7-4c406e1ee6ff",
   "metadata": {},
   "source": [
    "## Imputación de datos faltantes basada en promedio entre días anterior y posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c55f63-780e-4528-9572-12334333c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: ../data/plata/dataset_plata_horario_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Variables a imputar\n",
    "variables_objetivo = ['TEMP', 'HUM', 'PNM', 'DD', 'FF']\n",
    "\n",
    "df_interp = df_horario_completo.copy()\n",
    "\n",
    "# Asegurar FECHA y HORA correctas\n",
    "df_interp['FECHA'] = df_interp['FECHA_HORA'].dt.date\n",
    "df_interp['HORA'] = df_interp['FECHA_HORA'].dt.hour\n",
    "\n",
    "# Ordenar por estación, fecha y hora\n",
    "df_interp = df_interp.sort_values(by=['NOMBRE', 'FECHA', 'HORA'])\n",
    "\n",
    "# Función de imputación por promedio entre día anterior y posterior\n",
    "def imputar_valores(grupo):\n",
    "    grupo = grupo.copy()  # para evitar advertencias de SettingWithCopy\n",
    "    for var in variables_objetivo:\n",
    "        for idx, fila in grupo.iterrows():\n",
    "            if pd.isna(fila[var]):\n",
    "                hora = fila['HORA']\n",
    "                fecha = fila['FECHA']\n",
    "\n",
    "                # Buscar el valor del día anterior\n",
    "                val_ant = grupo[(grupo['HORA'] == hora) & (grupo['FECHA'] < fecha)][var].last_valid_index()\n",
    "                val_ant = grupo.at[val_ant, var] if val_ant is not None else None\n",
    "\n",
    "                # Buscar el valor del día posterior\n",
    "                val_post = grupo[(grupo['HORA'] == hora) & (grupo['FECHA'] > fecha)][var].first_valid_index()\n",
    "                val_post = grupo.at[val_post, var] if val_post is not None else None\n",
    "\n",
    "                # Asignar promedio o valor disponible\n",
    "                if val_ant is not None and val_post is not None:\n",
    "                    grupo.at[idx, var] = round((val_ant + val_post) / 2, 1)\n",
    "                elif val_ant is not None:\n",
    "                    grupo.at[idx, var] = val_ant\n",
    "                elif val_post is not None:\n",
    "                    grupo.at[idx, var] = val_post\n",
    "    return grupo\n",
    "\n",
    "# Aplicar por estación SIN include_groups\n",
    "df_interp = (\n",
    "    df_interp.groupby('NOMBRE', group_keys=False)\n",
    "    .apply(imputar_valores)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Redondear valores numéricos a 1 decimal\n",
    "for var in variables_objetivo:\n",
    "    df_interp[var] = df_interp[var].round(1)\n",
    "\n",
    "# Ajustar tipos de columnas\n",
    "df_interp['HORA'] = df_interp['HORA'].astype('int64')\n",
    "if 'estacion_archivo' in df_interp.columns:\n",
    "    df_interp['estacion_archivo'] = df_interp['estacion_archivo'].astype('int64', errors='ignore')\n",
    "\n",
    "# Exportar\n",
    "archivo_imputado = PLATA_DIR / \"dataset_plata_horario_final.csv\"\n",
    "df_interp.to_csv(archivo_imputado, index=False)\n",
    "print(f\"Archivo exportado: {archivo_imputado}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601075f8-481b-4421-86ea-08dde5c8ec10",
   "metadata": {},
   "source": [
    "## Generar archivo diario a partir de la imputación de los datos faltantes en el dato_horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25ddba3-bd7d-4118-bc51-312318bc688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas finales: ['ESTACION', 'FECHA', 'TEMP_MEAN', 'TEMP_MIN', 'TEMP_MAX', 'PNM_MEAN', 'PNM_MIN', 'PNM_MAX', 'HUM_MEAN', 'HUM_MIN', 'HUM_MAX', 'WIND_DIR_MEAN', 'WIND_DIR_MIN', 'WIND_DIR_MAX', 'WIND_SPEED_MEAN', 'WIND_SPEED_MIN', 'WIND_SPEED_MAX', 'TEMP_MEAN_NORM', 'PNM_MEAN_NORM', 'HUM_MEAN_NORM', 'WIND_DIR_MEAN_NORM', 'WIND_SPEED_MEAN_NORM']\n",
      "Filas: 2130 | Columnas: 22\n",
      "ESTACION\n",
      "CORRIENTES AERO            426\n",
      "ITUZAINGO                  426\n",
      "MERCEDES AERO (CTES)       426\n",
      "MONTE CASEROS AERO         426\n",
      "PASO DE LOS LIBRES AERO    426\n",
      "dtype: int64\n",
      "Archivo diario imputado exportado: ../data/plata/dataset_plata_diario_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Generar dataset diario imputado (todas las estaciones)\n",
    "\n",
    "# Agrupar por estación y fecha\n",
    "df_diario_imputado = df_interp.groupby(['NOMBRE', 'FECHA']).agg(\n",
    "    TEMP_MEAN=('TEMP', 'mean'),\n",
    "    TEMP_MIN=('TEMP', 'min'),\n",
    "    TEMP_MAX=('TEMP', 'max'),\n",
    "    PNM_MEAN=('PNM', 'mean'),\n",
    "    PNM_MIN=('PNM', 'min'),\n",
    "    PNM_MAX=('PNM', 'max'),\n",
    "    HUM_MEAN=('HUM', 'mean'),\n",
    "    HUM_MIN=('HUM', 'min'),\n",
    "    HUM_MAX=('HUM', 'max'),\n",
    "    WIND_DIR_MEAN=('DD', 'mean'),\n",
    "    WIND_DIR_MIN=('DD', 'min'),\n",
    "    WIND_DIR_MAX=('DD', 'max'),\n",
    "    WIND_SPEED_MEAN=('FF', 'mean'),\n",
    "    WIND_SPEED_MIN=('FF', 'min'),\n",
    "    WIND_SPEED_MAX=('FF', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Renombrar y ordenar\n",
    "df_diario_imputado.rename(columns={'NOMBRE':'ESTACION'}, inplace=True)\n",
    "df_diario_imputado['FECHA'] = pd.to_datetime(df_diario_imputado['FECHA'])\n",
    "df_diario_imputado = df_diario_imputado.sort_values(by=['ESTACION','FECHA']).reset_index(drop=True)\n",
    "\n",
    "# Ajustes de tipos y redondeo\n",
    "\n",
    "# Redondear medias a 1 decimal\n",
    "cols_float = ['TEMP_MEAN','PNM_MEAN','HUM_MEAN','WIND_DIR_MEAN','WIND_SPEED_MEAN']\n",
    "df_diario_imputado[cols_float] = df_diario_imputado[cols_float].round(1)\n",
    "\n",
    "# Convertir min y max a enteros\n",
    "cols_int = [\n",
    "    'TEMP_MIN','TEMP_MAX','PNM_MIN','PNM_MAX',\n",
    "    'HUM_MIN','HUM_MAX',\n",
    "    'WIND_DIR_MIN','WIND_DIR_MAX',\n",
    "    'WIND_SPEED_MIN','WIND_SPEED_MAX'\n",
    "]\n",
    "df_diario_imputado[cols_int] = df_diario_imputado[cols_int].round().astype(int)\n",
    "\n",
    "# Normalización Min-Max de las variables MEAN\n",
    "\n",
    "variables_mean = ['TEMP_MEAN','PNM_MEAN','HUM_MEAN','WIND_DIR_MEAN','WIND_SPEED_MEAN']\n",
    "for var in variables_mean:\n",
    "    col_norm = var + '_NORM'\n",
    "    min_val = df_diario_imputado[var].min()\n",
    "    max_val = df_diario_imputado[var].max()\n",
    "    df_diario_imputado[col_norm] = ((df_diario_imputado[var] - min_val) / (max_val - min_val)).round(5)\n",
    "\n",
    "# Validación y exportación\n",
    "\n",
    "print(\"\\nColumnas finales:\", df_diario_imputado.columns.tolist())\n",
    "print(\"Filas:\", len(df_diario_imputado), \"| Columnas:\", len(df_diario_imputado.columns))\n",
    "print(df_diario_imputado.groupby('ESTACION').size())\n",
    "\n",
    "# Guardar el dataset diario imputado completo\n",
    "archivo_diario_imputado = PLATA_DIR / \"dataset_plata_diario_final.csv\"\n",
    "df_diario_imputado.to_csv(archivo_diario_imputado, index=False)\n",
    "print(f\"Archivo diario imputado exportado: {archivo_diario_imputado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5a1e2-540a-4687-a19e-2fbad388c299",
   "metadata": {},
   "source": [
    "## Verificar las imputaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6171ed-7840-45f6-bebd-8b074f8307f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores restantes faltantes por variable:\n",
      "TEMP    0\n",
      "HUM     0\n",
      "PNM     0\n",
      "DD      0\n",
      "FF      0\n",
      "dtype: int64\n",
      "\n",
      "Ejemplos de filas con valores aún faltantes:\n",
      "Empty DataFrame\n",
      "Columns: [NOMBRE, FECHA_HORA, FECHA, HORA, TEMP, HUM, PNM, DD, FF, estacion_archivo]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Verificación de imputación final\n",
    "print(\"Valores restantes faltantes por variable:\")\n",
    "print(df_interp[variables_objetivo].isnull().sum())\n",
    "\n",
    "# Vista previa de algunos valores aún faltantes (si existen)\n",
    "print(\"\\nEjemplos de filas con valores aún faltantes:\")\n",
    "print(df_interp[df_interp[variables_objetivo].isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582557e9-6395-4024-bf21-354896d3d44d",
   "metadata": {},
   "source": [
    "# Contar imputaciones por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b35aff0-0b2a-4654-b75a-2da41925b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de imputaciones por variable:\n",
      " - TEMP: 450 valores imputados\n",
      " - HUM: 450 valores imputados\n",
      " - PNM: 450 valores imputados\n",
      " - DD: 450 valores imputados\n",
      " - FF: 450 valores imputados\n",
      "\n",
      "Ejemplos de imputaciones realizadas:\n",
      "\n",
      "Variable: TEMP\n",
      "               FECHA_HORA                   NOMBRE  TEMP\n",
      "39    2024-06-02 15:00:00          CORRIENTES AERO  27.8\n",
      "124   2024-06-06 04:00:00          CORRIENTES AERO  19.9\n",
      "423   2024-06-18 15:00:00          CORRIENTES AERO  21.5\n",
      "590   2024-06-25 14:00:00          CORRIENTES AERO  13.4\n",
      "716   2024-06-30 20:00:00          CORRIENTES AERO  11.1\n",
      "...                   ...                      ...   ...\n",
      "40312 2025-03-23 04:00:00  PASO DE LOS LIBRES AERO  20.4\n",
      "40313 2025-03-23 05:00:00  PASO DE LOS LIBRES AERO  19.9\n",
      "40314 2025-03-23 06:00:00  PASO DE LOS LIBRES AERO  19.6\n",
      "40315 2025-03-23 07:00:00  PASO DE LOS LIBRES AERO  20.0\n",
      "42057 2025-06-03 21:00:00  PASO DE LOS LIBRES AERO  15.8\n",
      "\n",
      "[450 rows x 3 columns]\n",
      "\n",
      "Variable: HUM\n",
      "               FECHA_HORA                   NOMBRE   HUM\n",
      "39    2024-06-02 15:00:00          CORRIENTES AERO  47.0\n",
      "124   2024-06-06 04:00:00          CORRIENTES AERO  89.0\n",
      "423   2024-06-18 15:00:00          CORRIENTES AERO  91.0\n",
      "590   2024-06-25 14:00:00          CORRIENTES AERO  74.0\n",
      "716   2024-06-30 20:00:00          CORRIENTES AERO  65.0\n",
      "...                   ...                      ...   ...\n",
      "40312 2025-03-23 04:00:00  PASO DE LOS LIBRES AERO  95.0\n",
      "40313 2025-03-23 05:00:00  PASO DE LOS LIBRES AERO  96.0\n",
      "40314 2025-03-23 06:00:00  PASO DE LOS LIBRES AERO  96.0\n",
      "40315 2025-03-23 07:00:00  PASO DE LOS LIBRES AERO  95.0\n",
      "42057 2025-06-03 21:00:00  PASO DE LOS LIBRES AERO  97.0\n",
      "\n",
      "[450 rows x 3 columns]\n",
      "\n",
      "Variable: PNM\n",
      "               FECHA_HORA                   NOMBRE     PNM\n",
      "39    2024-06-02 15:00:00          CORRIENTES AERO  1011.6\n",
      "124   2024-06-06 04:00:00          CORRIENTES AERO  1013.9\n",
      "423   2024-06-18 15:00:00          CORRIENTES AERO  1004.7\n",
      "590   2024-06-25 14:00:00          CORRIENTES AERO  1018.9\n",
      "716   2024-06-30 20:00:00          CORRIENTES AERO  1021.5\n",
      "...                   ...                      ...     ...\n",
      "40312 2025-03-23 04:00:00  PASO DE LOS LIBRES AERO  1010.5\n",
      "40313 2025-03-23 05:00:00  PASO DE LOS LIBRES AERO  1010.6\n",
      "40314 2025-03-23 06:00:00  PASO DE LOS LIBRES AERO  1011.3\n",
      "40315 2025-03-23 07:00:00  PASO DE LOS LIBRES AERO  1012.2\n",
      "42057 2025-06-03 21:00:00  PASO DE LOS LIBRES AERO  1014.3\n",
      "\n",
      "[450 rows x 3 columns]\n",
      "\n",
      "Variable: DD\n",
      "               FECHA_HORA                   NOMBRE     DD\n",
      "39    2024-06-02 15:00:00          CORRIENTES AERO   20.0\n",
      "124   2024-06-06 04:00:00          CORRIENTES AERO  110.0\n",
      "423   2024-06-18 15:00:00          CORRIENTES AERO   80.0\n",
      "590   2024-06-25 14:00:00          CORRIENTES AERO  180.0\n",
      "716   2024-06-30 20:00:00          CORRIENTES AERO   80.0\n",
      "...                   ...                      ...    ...\n",
      "40312 2025-03-23 04:00:00  PASO DE LOS LIBRES AERO    0.0\n",
      "40313 2025-03-23 05:00:00  PASO DE LOS LIBRES AERO   20.0\n",
      "40314 2025-03-23 06:00:00  PASO DE LOS LIBRES AERO    0.0\n",
      "40315 2025-03-23 07:00:00  PASO DE LOS LIBRES AERO  360.0\n",
      "42057 2025-06-03 21:00:00  PASO DE LOS LIBRES AERO   70.0\n",
      "\n",
      "[450 rows x 3 columns]\n",
      "\n",
      "Variable: FF\n",
      "               FECHA_HORA                   NOMBRE    FF\n",
      "39    2024-06-02 15:00:00          CORRIENTES AERO  19.0\n",
      "124   2024-06-06 04:00:00          CORRIENTES AERO   7.0\n",
      "423   2024-06-18 15:00:00          CORRIENTES AERO   7.0\n",
      "590   2024-06-25 14:00:00          CORRIENTES AERO  20.0\n",
      "716   2024-06-30 20:00:00          CORRIENTES AERO   4.0\n",
      "...                   ...                      ...   ...\n",
      "40312 2025-03-23 04:00:00  PASO DE LOS LIBRES AERO   0.0\n",
      "40313 2025-03-23 05:00:00  PASO DE LOS LIBRES AERO   4.0\n",
      "40314 2025-03-23 06:00:00  PASO DE LOS LIBRES AERO   0.0\n",
      "40315 2025-03-23 07:00:00  PASO DE LOS LIBRES AERO   9.0\n",
      "42057 2025-06-03 21:00:00  PASO DE LOS LIBRES AERO   6.0\n",
      "\n",
      "[450 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "imputaciones = {}\n",
    "for var in variables_objetivo:\n",
    "    # Detectar índices donde original es NaN pero imputado tiene valor\n",
    "    mask_imputado = df_horario_completo[var].isna() & df_interp[var].notna()\n",
    "    imputaciones[var] = mask_imputado.sum()\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"Resumen de imputaciones por variable:\")\n",
    "for var, count in imputaciones.items():\n",
    "    print(f\" - {var}: {count} valores imputados\")\n",
    "\n",
    "# Mostrar ejemplos comparativos (solo filas donde hubo imputación)\n",
    "print(\"\\nEjemplos de imputaciones realizadas:\")\n",
    "for var in variables_objetivo:\n",
    "    mask = df_horario_completo[var].isna() & df_interp[var].notna()\n",
    "    if mask.any():\n",
    "        print(f\"\\nVariable: {var}\")\n",
    "        print(df_interp.loc[mask, ['FECHA_HORA', 'NOMBRE', var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2e28a-e09d-4f54-931b-233ace89e1c0",
   "metadata": {},
   "source": [
    "# Visualización de imputación de los días faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fde00ba-b535-4101-aa38-7764982715d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Estación: PASO DE LOS LIBRES AERO ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                   NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "36708 2024-10-24 00:00:00  PASO DE LOS LIBRES AERO  22.2  80.5  1008.0  190.0  14.0\n",
      "36709 2024-10-24 01:00:00  PASO DE LOS LIBRES AERO  21.8  83.5  1007.6  160.0   7.5\n",
      "36710 2024-10-24 02:00:00  PASO DE LOS LIBRES AERO  21.4  83.5  1007.3  190.0  13.0\n",
      "36711 2024-10-24 03:00:00  PASO DE LOS LIBRES AERO  21.0  85.5  1006.8  190.0  12.0\n",
      "36712 2024-10-24 04:00:00  PASO DE LOS LIBRES AERO  20.8  87.0  1006.6  180.0  14.0\n",
      "36713 2024-10-24 05:00:00  PASO DE LOS LIBRES AERO  20.5  88.5  1006.8  180.0  14.0\n",
      "36714 2024-10-24 06:00:00  PASO DE LOS LIBRES AERO  20.2  89.0  1007.0  180.0  15.0\n",
      "36715 2024-10-24 07:00:00  PASO DE LOS LIBRES AERO  20.9  88.5  1007.4  190.0  12.0\n",
      "36716 2024-10-24 08:00:00  PASO DE LOS LIBRES AERO  22.5  83.0  1007.9  150.0  13.0\n",
      "36717 2024-10-24 09:00:00  PASO DE LOS LIBRES AERO  24.6  75.5  1008.0  135.0  16.0\n",
      "36718 2024-10-24 10:00:00  PASO DE LOS LIBRES AERO  25.5  73.5  1007.7  105.0  12.0\n",
      "36719 2024-10-24 11:00:00  PASO DE LOS LIBRES AERO  27.3  65.0  1007.5  140.0  12.0\n",
      "36720 2024-10-24 12:00:00  PASO DE LOS LIBRES AERO  28.7  62.0  1007.0  150.0  10.0\n",
      "36721 2024-10-24 13:00:00  PASO DE LOS LIBRES AERO  29.6  58.0  1006.3  110.0  14.0\n",
      "36722 2024-10-24 14:00:00  PASO DE LOS LIBRES AERO  31.0  55.5  1005.4  305.0  15.5\n",
      "36723 2024-10-24 15:00:00  PASO DE LOS LIBRES AERO  31.4  54.0  1004.4  325.0  18.5\n",
      "36724 2024-10-24 16:00:00  PASO DE LOS LIBRES AERO  31.4  50.0  1003.6  285.0  23.5\n",
      "36725 2024-10-24 17:00:00  PASO DE LOS LIBRES AERO  31.5  51.5  1003.2  315.0  18.5\n",
      "36726 2024-10-24 18:00:00  PASO DE LOS LIBRES AERO  30.7  52.0  1003.4  315.0  15.0\n",
      "36727 2024-10-24 19:00:00  PASO DE LOS LIBRES AERO  28.4  64.0  1004.1  155.0  10.0\n",
      "36728 2024-10-24 20:00:00  PASO DE LOS LIBRES AERO  25.4  60.0  1005.6  140.0  23.5\n",
      "36729 2024-10-24 21:00:00  PASO DE LOS LIBRES AERO  24.4  73.5  1006.5  125.0  21.5\n",
      "36730 2024-10-24 22:00:00  PASO DE LOS LIBRES AERO  24.4  69.5  1007.4  125.0  27.0\n",
      "36731 2024-10-24 23:00:00  PASO DE LOS LIBRES AERO  21.8  74.5  1007.5  115.0  21.5\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                   NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "37692 2024-12-04 00:00:00  PASO DE LOS LIBRES AERO  19.0  70.5  1011.4  145.0  13.0\n",
      "37693 2024-12-04 01:00:00  PASO DE LOS LIBRES AERO  18.7  71.0  1011.5  135.0  12.0\n",
      "37694 2024-12-04 02:00:00  PASO DE LOS LIBRES AERO  17.4  78.0  1011.6  125.0   8.0\n",
      "37695 2024-12-04 03:00:00  PASO DE LOS LIBRES AERO  16.7  79.5  1011.8  115.0  10.0\n",
      "37696 2024-12-04 04:00:00  PASO DE LOS LIBRES AERO  16.2  82.5  1011.6  115.0  13.0\n",
      "37697 2024-12-04 05:00:00  PASO DE LOS LIBRES AERO  16.6  76.5  1011.8  115.0  16.0\n",
      "37698 2024-12-04 06:00:00  PASO DE LOS LIBRES AERO  16.4  78.5  1012.2  115.0   9.5\n",
      "37699 2024-12-04 07:00:00  PASO DE LOS LIBRES AERO  17.8  81.0  1012.7  105.0   8.5\n",
      "37700 2024-12-04 08:00:00  PASO DE LOS LIBRES AERO  20.5  64.5  1012.8   80.0  16.0\n",
      "37701 2024-12-04 09:00:00  PASO DE LOS LIBRES AERO  22.7  60.5  1012.8   90.0  16.0\n",
      "37702 2024-12-04 10:00:00  PASO DE LOS LIBRES AERO  24.4  55.0  1012.8   90.0  14.0\n",
      "37703 2024-12-04 11:00:00  PASO DE LOS LIBRES AERO  25.8  52.0  1012.8  115.0  15.0\n",
      "37704 2024-12-04 12:00:00  PASO DE LOS LIBRES AERO  26.6  52.0  1012.2  115.0  14.0\n",
      "37705 2024-12-04 13:00:00  PASO DE LOS LIBRES AERO  27.4  51.5  1011.5  115.0  16.0\n",
      "37706 2024-12-04 14:00:00  PASO DE LOS LIBRES AERO  27.8  52.0  1010.8  125.0  20.5\n",
      "37707 2024-12-04 15:00:00  PASO DE LOS LIBRES AERO  28.3  53.5  1010.1  125.0  16.5\n",
      "37708 2024-12-04 16:00:00  PASO DE LOS LIBRES AERO  28.4  50.5  1009.2   90.0  16.0\n",
      "37709 2024-12-04 17:00:00  PASO DE LOS LIBRES AERO  28.0  53.0  1009.0  125.0  17.5\n",
      "37710 2024-12-04 18:00:00  PASO DE LOS LIBRES AERO  27.4  56.5  1008.6  115.0  15.0\n",
      "37711 2024-12-04 19:00:00  PASO DE LOS LIBRES AERO  26.6  58.0  1009.0  125.0   9.0\n",
      "37712 2024-12-04 20:00:00  PASO DE LOS LIBRES AERO  24.6  67.5  1009.0  115.0   8.5\n",
      "37713 2024-12-04 21:00:00  PASO DE LOS LIBRES AERO  23.4  72.0  1009.0  115.0  11.5\n",
      "37714 2024-12-04 22:00:00  PASO DE LOS LIBRES AERO  22.5  74.0  1009.2  115.0  10.5\n",
      "37715 2024-12-04 23:00:00  PASO DE LOS LIBRES AERO  21.9  79.5  1009.3  110.0  12.5\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                   NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "37860 2024-12-11 00:00:00  PASO DE LOS LIBRES AERO  20.2  75.0  1012.2  135.0   7.5\n",
      "37861 2024-12-11 01:00:00  PASO DE LOS LIBRES AERO  19.4  78.5  1012.0  135.0   6.5\n",
      "37862 2024-12-11 02:00:00  PASO DE LOS LIBRES AERO  19.2  82.0  1011.8  100.0   9.0\n",
      "37863 2024-12-11 03:00:00  PASO DE LOS LIBRES AERO  19.1  84.0  1011.8  115.0  13.0\n",
      "37864 2024-12-11 04:00:00  PASO DE LOS LIBRES AERO  19.1  84.5  1011.9  115.0  14.0\n",
      "37865 2024-12-11 05:00:00  PASO DE LOS LIBRES AERO  18.8  88.5  1012.3  115.0  13.0\n",
      "37866 2024-12-11 06:00:00  PASO DE LOS LIBRES AERO  18.9  88.0  1012.6  115.0  14.0\n",
      "37867 2024-12-11 07:00:00  PASO DE LOS LIBRES AERO  20.0  83.0  1013.0  115.0  14.0\n",
      "37868 2024-12-11 08:00:00  PASO DE LOS LIBRES AERO  21.6  77.5  1013.4   90.0  16.0\n",
      "37869 2024-12-11 09:00:00  PASO DE LOS LIBRES AERO  23.1  74.0  1013.4   90.0  17.5\n",
      "37870 2024-12-11 10:00:00  PASO DE LOS LIBRES AERO  25.0  68.0  1013.2   95.0  17.0\n",
      "37871 2024-12-11 11:00:00  PASO DE LOS LIBRES AERO  26.7  62.0  1012.8  125.0  16.0\n",
      "37872 2024-12-11 12:00:00  PASO DE LOS LIBRES AERO  28.0  57.5  1012.4   95.0  13.0\n",
      "37873 2024-12-11 13:00:00  PASO DE LOS LIBRES AERO  28.7  56.0  1012.1  105.0  14.0\n",
      "37874 2024-12-11 14:00:00  PASO DE LOS LIBRES AERO  29.6  48.5  1011.0  135.0  16.0\n",
      "37875 2024-12-11 15:00:00  PASO DE LOS LIBRES AERO  30.7  46.0  1010.2  115.0  15.5\n",
      "37876 2024-12-11 16:00:00  PASO DE LOS LIBRES AERO  30.4  48.5  1009.5  125.0  14.0\n",
      "37877 2024-12-11 17:00:00  PASO DE LOS LIBRES AERO  30.5  46.5  1008.7  115.0  13.0\n",
      "37878 2024-12-11 18:00:00  PASO DE LOS LIBRES AERO  30.0  44.5  1008.2  115.0  12.0\n",
      "37879 2024-12-11 19:00:00  PASO DE LOS LIBRES AERO  29.2  48.5  1008.1  105.0  12.0\n",
      "37880 2024-12-11 20:00:00  PASO DE LOS LIBRES AERO  26.6  58.0  1008.4   95.0   7.5\n",
      "37881 2024-12-11 21:00:00  PASO DE LOS LIBRES AERO  25.0  66.0  1008.8   80.0  10.0\n",
      "37882 2024-12-11 22:00:00  PASO DE LOS LIBRES AERO  23.8  71.0  1009.1   80.0   8.5\n",
      "37883 2024-12-11 23:00:00  PASO DE LOS LIBRES AERO  23.4  73.5  1009.2   90.0  10.0\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                   NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "38724 2025-01-16 00:00:00  PASO DE LOS LIBRES AERO  25.6  72.0  1008.1   70.0  14.0\n",
      "38725 2025-01-16 01:00:00  PASO DE LOS LIBRES AERO  24.9  74.0  1008.2   55.0  11.0\n",
      "38726 2025-01-16 02:00:00  PASO DE LOS LIBRES AERO  23.8  79.5  1008.2   80.0   9.0\n",
      "38727 2025-01-16 03:00:00  PASO DE LOS LIBRES AERO  23.0  82.5  1007.9   45.0   5.5\n",
      "38728 2025-01-16 04:00:00  PASO DE LOS LIBRES AERO  22.6  83.5  1007.8   45.0   4.5\n",
      "38729 2025-01-16 05:00:00  PASO DE LOS LIBRES AERO  21.8  86.0  1008.2   90.0   8.5\n",
      "38730 2025-01-16 06:00:00  PASO DE LOS LIBRES AERO  22.0  89.0  1008.7  100.0   7.5\n",
      "38731 2025-01-16 07:00:00  PASO DE LOS LIBRES AERO  22.5  88.5  1009.2  105.0   6.5\n",
      "38732 2025-01-16 08:00:00  PASO DE LOS LIBRES AERO  24.8  78.5  1009.8   90.0  11.0\n",
      "38733 2025-01-16 09:00:00  PASO DE LOS LIBRES AERO  27.8  66.0  1010.2   80.0  14.0\n",
      "38734 2025-01-16 10:00:00  PASO DE LOS LIBRES AERO  30.1  57.5  1010.2   80.0   9.0\n",
      "38735 2025-01-16 11:00:00  PASO DE LOS LIBRES AERO  31.8  50.0  1009.8   80.0   9.0\n",
      "38736 2025-01-16 12:00:00  PASO DE LOS LIBRES AERO  33.4  46.0  1009.4  125.0  11.0\n",
      "38737 2025-01-16 13:00:00  PASO DE LOS LIBRES AERO  34.4  42.0  1009.0  135.0  17.0\n",
      "38738 2025-01-16 14:00:00  PASO DE LOS LIBRES AERO  35.1  38.5  1008.1  170.0  19.5\n",
      "38739 2025-01-16 15:00:00  PASO DE LOS LIBRES AERO  35.4  37.5  1007.5  185.0  17.0\n",
      "38740 2025-01-16 16:00:00  PASO DE LOS LIBRES AERO  36.4  33.0  1007.0  145.0  18.5\n",
      "38741 2025-01-16 17:00:00  PASO DE LOS LIBRES AERO  36.3  33.0  1006.5  135.0  15.0\n",
      "38742 2025-01-16 18:00:00  PASO DE LOS LIBRES AERO  36.1  35.5  1006.3  115.0  13.0\n",
      "38743 2025-01-16 19:00:00  PASO DE LOS LIBRES AERO  34.8  38.5  1006.4   95.0  15.0\n",
      "38744 2025-01-16 20:00:00  PASO DE LOS LIBRES AERO  31.8  48.5  1007.2  105.0  10.0\n",
      "38745 2025-01-16 21:00:00  PASO DE LOS LIBRES AERO  30.5  51.5  1007.6   95.0   8.5\n",
      "38746 2025-01-16 22:00:00  PASO DE LOS LIBRES AERO  29.5  56.0  1008.0   70.0   8.5\n",
      "38747 2025-01-16 23:00:00  PASO DE LOS LIBRES AERO  28.1  61.0  1008.7   90.0   9.5\n",
      "\n",
      "=== Estación: CORRIENTES AERO ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA           NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "3480 2024-10-24 00:00:00  CORRIENTES AERO  23.4  73.5  1007.8  175.0  10.0\n",
      "3481 2024-10-24 01:00:00  CORRIENTES AERO  22.6  79.5  1007.7  185.0  10.0\n",
      "3482 2024-10-24 02:00:00  CORRIENTES AERO  21.8  87.0  1007.2  185.0  11.0\n",
      "3483 2024-10-24 03:00:00  CORRIENTES AERO  21.6  85.5  1006.7   50.0   5.5\n",
      "3484 2024-10-24 04:00:00  CORRIENTES AERO  21.6  85.5  1006.4   40.0   4.5\n",
      "3485 2024-10-24 05:00:00  CORRIENTES AERO  21.2  87.0  1006.3   40.0   3.5\n",
      "3486 2024-10-24 06:00:00  CORRIENTES AERO  20.2  91.0  1006.6   30.0   5.0\n",
      "3487 2024-10-24 07:00:00  CORRIENTES AERO  21.0  86.0  1007.1   30.0   5.0\n",
      "3488 2024-10-24 08:00:00  CORRIENTES AERO  23.8  81.5  1007.3   25.0   6.5\n",
      "3489 2024-10-24 09:00:00  CORRIENTES AERO  26.1  68.5  1007.2   85.0  10.5\n",
      "3490 2024-10-24 10:00:00  CORRIENTES AERO  28.1  57.0  1007.0   75.0  14.5\n",
      "3491 2024-10-24 11:00:00  CORRIENTES AERO  29.6  55.5  1006.8   20.0  14.5\n",
      "3492 2024-10-24 12:00:00  CORRIENTES AERO  30.6  51.0  1006.2   55.0  17.5\n",
      "3493 2024-10-24 13:00:00  CORRIENTES AERO  31.6  47.5  1005.4   95.0  16.5\n",
      "3494 2024-10-24 14:00:00  CORRIENTES AERO  32.6  43.0  1004.6   75.0  16.5\n",
      "3495 2024-10-24 15:00:00  CORRIENTES AERO  32.2  46.5  1004.0  160.0  16.5\n",
      "3496 2024-10-24 16:00:00  CORRIENTES AERO  33.0  40.0  1003.3  125.0  18.5\n",
      "3497 2024-10-24 17:00:00  CORRIENTES AERO  32.2  40.5  1003.0  130.0  17.5\n",
      "3498 2024-10-24 18:00:00  CORRIENTES AERO  31.4  42.5  1003.4  120.0  15.0\n",
      "3499 2024-10-24 19:00:00  CORRIENTES AERO  29.8  49.0  1003.8  150.0  10.0\n",
      "3500 2024-10-24 20:00:00  CORRIENTES AERO  27.6  59.0  1004.7  145.0   5.5\n",
      "3501 2024-10-24 21:00:00  CORRIENTES AERO  26.4  62.0  1006.0  155.0  23.0\n",
      "3502 2024-10-24 22:00:00  CORRIENTES AERO  25.0  64.5  1006.9  140.0  19.5\n",
      "3503 2024-10-24 23:00:00  CORRIENTES AERO  24.2  66.0  1007.6  140.0  18.5\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA           NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "4464 2024-12-04 00:00:00  CORRIENTES AERO  20.0  72.5  1010.6  165.0   7.0\n",
      "4465 2024-12-04 01:00:00  CORRIENTES AERO  19.5  75.5  1010.4  175.0  10.0\n",
      "4466 2024-12-04 02:00:00  CORRIENTES AERO  19.6  73.0  1010.2  175.0  10.0\n",
      "4467 2024-12-04 03:00:00  CORRIENTES AERO  19.4  73.5  1010.0  175.0  11.0\n",
      "4468 2024-12-04 04:00:00  CORRIENTES AERO  19.2  77.0  1009.9  165.0   7.5\n",
      "4469 2024-12-04 05:00:00  CORRIENTES AERO  19.2  75.0  1009.6  160.0  13.0\n",
      "4470 2024-12-04 06:00:00  CORRIENTES AERO  19.2  76.5  1009.8  135.0  14.0\n",
      "4471 2024-12-04 07:00:00  CORRIENTES AERO  19.9  75.5  1010.0  160.0  14.5\n",
      "4472 2024-12-04 08:00:00  CORRIENTES AERO  21.1  75.5  1010.6  140.0  15.0\n",
      "4473 2024-12-04 09:00:00  CORRIENTES AERO  23.6  69.5  1010.6  130.0  18.5\n",
      "4474 2024-12-04 10:00:00  CORRIENTES AERO  25.0  64.5  1011.0  115.0  21.5\n",
      "4475 2024-12-04 11:00:00  CORRIENTES AERO  26.4  57.0  1010.8  125.0  18.5\n",
      "4476 2024-12-04 12:00:00  CORRIENTES AERO  27.0  55.5  1010.5  125.0  17.5\n",
      "4477 2024-12-04 13:00:00  CORRIENTES AERO  28.0  51.5  1010.0  125.0  18.5\n",
      "4478 2024-12-04 14:00:00  CORRIENTES AERO  28.2  50.5  1009.8  120.0  20.5\n",
      "4479 2024-12-04 15:00:00  CORRIENTES AERO  29.1  46.5  1008.6  125.0  21.5\n",
      "4480 2024-12-04 16:00:00  CORRIENTES AERO  29.3  43.5  1007.8  125.0  22.5\n",
      "4481 2024-12-04 17:00:00  CORRIENTES AERO  29.0  46.0  1007.1  125.0  21.5\n",
      "4482 2024-12-04 18:00:00  CORRIENTES AERO  28.3  47.5  1006.8  135.0  17.0\n",
      "4483 2024-12-04 19:00:00  CORRIENTES AERO  27.4  53.0  1006.6  120.0  16.0\n",
      "4484 2024-12-04 20:00:00  CORRIENTES AERO  25.5  61.5  1007.0  120.0  11.0\n",
      "4485 2024-12-04 21:00:00  CORRIENTES AERO  24.2  69.0  1007.2  115.0  11.0\n",
      "4486 2024-12-04 22:00:00  CORRIENTES AERO  23.6  73.0  1007.4  110.0  12.0\n",
      "4487 2024-12-04 23:00:00  CORRIENTES AERO  22.6  79.5  1007.8  130.0   9.0\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA           NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "4632 2024-12-11 00:00:00  CORRIENTES AERO  21.8  88.5  1009.2  115.0  13.0\n",
      "4633 2024-12-11 01:00:00  CORRIENTES AERO  21.2  88.5  1010.8  195.0   6.5\n",
      "4634 2024-12-11 02:00:00  CORRIENTES AERO  20.5  90.5  1010.6  185.0   6.0\n",
      "4635 2024-12-11 03:00:00  CORRIENTES AERO  20.0  94.5  1010.4  190.0   7.5\n",
      "4636 2024-12-11 04:00:00  CORRIENTES AERO  20.6  88.0  1010.2   60.0   4.5\n",
      "4637 2024-12-11 05:00:00  CORRIENTES AERO  20.2  89.5  1010.2  175.0   7.5\n",
      "4638 2024-12-11 06:00:00  CORRIENTES AERO  19.6  89.5  1010.6  170.0   9.0\n",
      "4639 2024-12-11 07:00:00  CORRIENTES AERO  20.4  87.0  1011.0  145.0   6.5\n",
      "4640 2024-12-11 08:00:00  CORRIENTES AERO  22.6  80.0  1011.3  145.0  11.0\n",
      "4641 2024-12-11 09:00:00  CORRIENTES AERO  25.4  62.5  1011.6  130.0  13.0\n",
      "4642 2024-12-11 10:00:00  CORRIENTES AERO  26.8  59.5  1011.6  120.0  18.0\n",
      "4643 2024-12-11 11:00:00  CORRIENTES AERO  28.8  59.5  1011.3  120.0  17.0\n",
      "4644 2024-12-11 12:00:00  CORRIENTES AERO  29.0  56.5  1010.9  100.0  18.0\n",
      "4645 2024-12-11 13:00:00  CORRIENTES AERO  29.8  54.5  1010.1  120.0  14.0\n",
      "4646 2024-12-11 14:00:00  CORRIENTES AERO  30.4  54.0  1009.3  125.0  15.0\n",
      "4647 2024-12-11 15:00:00  CORRIENTES AERO  30.8  53.0  1008.6  110.0  12.0\n",
      "4648 2024-12-11 16:00:00  CORRIENTES AERO  30.0  54.0  1007.2  145.0  13.0\n",
      "4649 2024-12-11 17:00:00  CORRIENTES AERO  29.9  55.0  1007.4  115.0  11.0\n",
      "4650 2024-12-11 18:00:00  CORRIENTES AERO  29.4  59.5  1006.6   95.0  11.0\n",
      "4651 2024-12-11 19:00:00  CORRIENTES AERO  29.0  58.5  1006.0  115.0  11.0\n",
      "4652 2024-12-11 20:00:00  CORRIENTES AERO  26.8  70.0  1007.0  160.0   9.0\n",
      "4653 2024-12-11 21:00:00  CORRIENTES AERO  26.0  74.0  1007.1  140.0  10.0\n",
      "4654 2024-12-11 22:00:00  CORRIENTES AERO  25.2  79.0  1007.6   95.0  20.5\n",
      "4655 2024-12-11 23:00:00  CORRIENTES AERO  24.2  75.0  1008.2   85.0  14.0\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA           NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "5496 2025-01-16 00:00:00  CORRIENTES AERO  26.5  63.0  1006.8  105.0  11.0\n",
      "5497 2025-01-16 01:00:00  CORRIENTES AERO  25.6  68.5  1006.8   90.0   6.5\n",
      "5498 2025-01-16 02:00:00  CORRIENTES AERO  24.2  77.5  1006.6  125.0   7.5\n",
      "5499 2025-01-16 03:00:00  CORRIENTES AERO  23.6  80.0  1006.4  115.0   8.0\n",
      "5500 2025-01-16 04:00:00  CORRIENTES AERO  22.5  86.0  1006.1  115.0   6.5\n",
      "5501 2025-01-16 05:00:00  CORRIENTES AERO  22.0  87.0  1006.2  115.0   7.5\n",
      "5502 2025-01-16 06:00:00  CORRIENTES AERO  21.8  86.0  1006.8  140.0   8.0\n",
      "5503 2025-01-16 07:00:00  CORRIENTES AERO  22.2  85.5  1007.4  140.0   8.0\n",
      "5504 2025-01-16 08:00:00  CORRIENTES AERO  24.1  75.0  1008.2  140.0  11.0\n",
      "5505 2025-01-16 09:00:00  CORRIENTES AERO  27.1  69.0  1008.6  105.0   7.5\n",
      "5506 2025-01-16 10:00:00  CORRIENTES AERO  30.0  55.5  1008.6   55.0   8.5\n",
      "5507 2025-01-16 11:00:00  CORRIENTES AERO  32.4  45.0  1008.4   65.0   6.5\n",
      "5508 2025-01-16 12:00:00  CORRIENTES AERO  33.6  42.5  1007.9  165.0  10.0\n",
      "5509 2025-01-16 13:00:00  CORRIENTES AERO  35.8  32.0  1007.4  285.0   9.0\n",
      "5510 2025-01-16 14:00:00  CORRIENTES AERO  36.6  29.5  1006.7  165.0   8.0\n",
      "5511 2025-01-16 15:00:00  CORRIENTES AERO  36.0  31.0  1006.2   85.0   9.0\n",
      "5512 2025-01-16 16:00:00  CORRIENTES AERO  37.2  28.0  1005.6  265.0  14.0\n",
      "5513 2025-01-16 17:00:00  CORRIENTES AERO  37.1  26.0  1005.0   95.0  17.0\n",
      "5514 2025-01-16 18:00:00  CORRIENTES AERO  36.5  27.5  1004.7  130.0  13.0\n",
      "5515 2025-01-16 19:00:00  CORRIENTES AERO  35.2  31.5  1004.8  130.0  17.0\n",
      "5516 2025-01-16 20:00:00  CORRIENTES AERO  33.1  37.0  1005.6  125.0  12.0\n",
      "5517 2025-01-16 21:00:00  CORRIENTES AERO  31.4  45.0  1006.0  125.0  12.0\n",
      "5518 2025-01-16 22:00:00  CORRIENTES AERO  30.2  50.5  1006.6  125.0   9.0\n",
      "5519 2025-01-16 23:00:00  CORRIENTES AERO  29.3  52.0  1007.2  125.0  10.0\n",
      "\n",
      "=== Estación: MONTE CASEROS AERO ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA              NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "26484 2024-10-24 00:00:00  MONTE CASEROS AERO  21.8  80.5  1007.8  190.0  14.0\n",
      "26485 2024-10-24 01:00:00  MONTE CASEROS AERO  21.1  84.5  1007.4  180.0  17.5\n",
      "26486 2024-10-24 02:00:00  MONTE CASEROS AERO  21.0  84.0  1006.8  180.0  13.0\n",
      "26487 2024-10-24 03:00:00  MONTE CASEROS AERO  20.6  86.0  1006.8  180.0  11.0\n",
      "26488 2024-10-24 04:00:00  MONTE CASEROS AERO  20.0  87.5  1006.6  200.0  12.0\n",
      "26489 2024-10-24 05:00:00  MONTE CASEROS AERO  19.6  89.5  1006.6  190.0   9.0\n",
      "26490 2024-10-24 06:00:00  MONTE CASEROS AERO  19.3  89.0  1006.6  190.0   8.0\n",
      "26491 2024-10-24 07:00:00  MONTE CASEROS AERO  20.0  87.0  1007.3  180.0  10.0\n",
      "26492 2024-10-24 08:00:00  MONTE CASEROS AERO  22.2  80.0  1007.6  160.0  11.0\n",
      "26493 2024-10-24 09:00:00  MONTE CASEROS AERO  24.1  72.0  1007.6  135.0   8.5\n",
      "26494 2024-10-24 10:00:00  MONTE CASEROS AERO  25.7  65.0  1007.4  115.0  15.0\n",
      "26495 2024-10-24 11:00:00  MONTE CASEROS AERO  27.0  63.5  1007.2  135.0  15.5\n",
      "26496 2024-10-24 12:00:00  MONTE CASEROS AERO  28.1  60.5  1006.6   90.0  13.5\n",
      "26497 2024-10-24 13:00:00  MONTE CASEROS AERO  29.3  57.5  1006.0  100.0  15.5\n",
      "26498 2024-10-24 14:00:00  MONTE CASEROS AERO  30.7  50.0  1005.1  135.0  19.5\n",
      "26499 2024-10-24 15:00:00  MONTE CASEROS AERO  31.3  49.0  1004.2  160.0  20.5\n",
      "26500 2024-10-24 16:00:00  MONTE CASEROS AERO  31.1  48.5  1003.0  155.0  23.0\n",
      "26501 2024-10-24 17:00:00  MONTE CASEROS AERO  31.4  46.0  1002.4  145.0  21.5\n",
      "26502 2024-10-24 18:00:00  MONTE CASEROS AERO  29.6  53.5  1003.2  125.0  37.0\n",
      "26503 2024-10-24 19:00:00  MONTE CASEROS AERO  26.9  57.0  1004.5  125.0  29.5\n",
      "26504 2024-10-24 20:00:00  MONTE CASEROS AERO  25.9  58.5  1005.6  140.0  26.0\n",
      "26505 2024-10-24 21:00:00  MONTE CASEROS AERO  24.2  60.5  1006.8  140.0  29.0\n",
      "26506 2024-10-24 22:00:00  MONTE CASEROS AERO  22.5  65.5  1007.8  190.0  24.0\n",
      "26507 2024-10-24 23:00:00  MONTE CASEROS AERO  18.9  76.5  1008.5  170.0  24.0\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA              NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "27468 2024-12-04 00:00:00  MONTE CASEROS AERO  18.9  70.5  1011.7  135.0  15.5\n",
      "27469 2024-12-04 01:00:00  MONTE CASEROS AERO  18.7  68.0  1011.5  135.0  16.0\n",
      "27470 2024-12-04 02:00:00  MONTE CASEROS AERO  17.6  74.5  1011.2  145.0  15.0\n",
      "27471 2024-12-04 03:00:00  MONTE CASEROS AERO  17.5  74.0  1011.4  115.0   7.5\n",
      "27472 2024-12-04 04:00:00  MONTE CASEROS AERO  16.7  79.0  1011.6  115.0   7.5\n",
      "27473 2024-12-04 05:00:00  MONTE CASEROS AERO  16.1  80.5  1012.0  100.0   6.5\n",
      "27474 2024-12-04 06:00:00  MONTE CASEROS AERO  15.4  78.0  1012.2  100.0   9.5\n",
      "27475 2024-12-04 07:00:00  MONTE CASEROS AERO  17.1  72.5  1012.6   90.0   8.5\n",
      "27476 2024-12-04 08:00:00  MONTE CASEROS AERO  19.6  63.5  1013.0   90.0  15.5\n",
      "27477 2024-12-04 09:00:00  MONTE CASEROS AERO  21.5  59.5  1013.2  115.0  10.5\n",
      "27478 2024-12-04 10:00:00  MONTE CASEROS AERO  23.6  55.5  1013.0  125.0  18.0\n",
      "27479 2024-12-04 11:00:00  MONTE CASEROS AERO  24.6  52.5  1012.9  115.0  17.0\n",
      "27480 2024-12-04 12:00:00  MONTE CASEROS AERO  25.8  45.5  1012.3  125.0  22.0\n",
      "27481 2024-12-04 13:00:00  MONTE CASEROS AERO  26.7  44.5  1011.5  115.0  19.5\n",
      "27482 2024-12-04 14:00:00  MONTE CASEROS AERO  27.4  43.5  1010.9  150.0  17.5\n",
      "27483 2024-12-04 15:00:00  MONTE CASEROS AERO  27.2  45.5  1010.1  150.0  19.5\n",
      "27484 2024-12-04 16:00:00  MONTE CASEROS AERO  27.1  48.5  1009.2  135.0  17.0\n",
      "27485 2024-12-04 17:00:00  MONTE CASEROS AERO  27.0  50.0  1008.7  125.0  18.5\n",
      "27486 2024-12-04 18:00:00  MONTE CASEROS AERO  26.8  51.5  1008.8  115.0  16.0\n",
      "27487 2024-12-04 19:00:00  MONTE CASEROS AERO  26.3  54.0  1008.6  125.0  14.0\n",
      "27488 2024-12-04 20:00:00  MONTE CASEROS AERO  24.9  60.5  1008.7  115.0  12.0\n",
      "27489 2024-12-04 21:00:00  MONTE CASEROS AERO  23.8  66.0  1008.8  105.0  12.0\n",
      "27490 2024-12-04 22:00:00  MONTE CASEROS AERO  22.8  73.0  1009.2  115.0  12.0\n",
      "27491 2024-12-04 23:00:00  MONTE CASEROS AERO  22.3  71.5  1009.2  125.0  12.0\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA              NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "27636 2024-12-11 00:00:00  MONTE CASEROS AERO  18.2  82.5  1012.3  170.0   5.5\n",
      "27637 2024-12-11 01:00:00  MONTE CASEROS AERO  18.2  81.5  1012.2  160.0   6.5\n",
      "27638 2024-12-11 02:00:00  MONTE CASEROS AERO  17.3  85.0  1012.2  180.0   5.5\n",
      "27639 2024-12-11 03:00:00  MONTE CASEROS AERO  17.8  81.0  1011.8  160.0   9.0\n",
      "27640 2024-12-11 04:00:00  MONTE CASEROS AERO  17.4  82.0  1012.0  160.0   8.0\n",
      "27641 2024-12-11 05:00:00  MONTE CASEROS AERO  17.2  83.0  1012.4  135.0  11.0\n",
      "27642 2024-12-11 06:00:00  MONTE CASEROS AERO  16.9  86.0  1012.7  125.0   9.5\n",
      "27643 2024-12-11 07:00:00  MONTE CASEROS AERO  18.3  83.5  1013.0  115.0  12.0\n",
      "27644 2024-12-11 08:00:00  MONTE CASEROS AERO  20.0  77.5  1013.2  125.0  14.5\n",
      "27645 2024-12-11 09:00:00  MONTE CASEROS AERO  22.7  66.5  1013.5  100.0  11.0\n",
      "27646 2024-12-11 10:00:00  MONTE CASEROS AERO  24.6  62.0  1013.2   90.0  13.0\n",
      "27647 2024-12-11 11:00:00  MONTE CASEROS AERO  26.5  60.0  1012.9   90.0  13.0\n",
      "27648 2024-12-11 12:00:00  MONTE CASEROS AERO  27.8  53.5  1012.3  115.0  13.0\n",
      "27649 2024-12-11 13:00:00  MONTE CASEROS AERO  29.0  46.5  1012.0  105.0  13.0\n",
      "27650 2024-12-11 14:00:00  MONTE CASEROS AERO  29.6  43.5  1011.3  115.0  13.0\n",
      "27651 2024-12-11 15:00:00  MONTE CASEROS AERO  30.2  42.0  1010.2  125.0  11.0\n",
      "27652 2024-12-11 16:00:00  MONTE CASEROS AERO  30.7  39.0  1009.6  100.0  14.0\n",
      "27653 2024-12-11 17:00:00  MONTE CASEROS AERO  30.4  40.5  1008.9  115.0  13.0\n",
      "27654 2024-12-11 18:00:00  MONTE CASEROS AERO  29.9  40.5  1008.2   95.0  16.0\n",
      "27655 2024-12-11 19:00:00  MONTE CASEROS AERO  28.9  42.5  1008.1   95.0  13.0\n",
      "27656 2024-12-11 20:00:00  MONTE CASEROS AERO  27.2  49.5  1008.0  105.0   7.0\n",
      "27657 2024-12-11 21:00:00  MONTE CASEROS AERO  25.8  58.0  1008.6  115.0   8.5\n",
      "27658 2024-12-11 22:00:00  MONTE CASEROS AERO  25.1  59.5  1009.0   70.0  11.0\n",
      "27659 2024-12-11 23:00:00  MONTE CASEROS AERO  24.2  64.5  1009.2   90.0   7.5\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA              NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "28500 2025-01-16 00:00:00  MONTE CASEROS AERO  26.1  59.0  1008.2   90.0  12.0\n",
      "28501 2025-01-16 01:00:00  MONTE CASEROS AERO  25.2  65.5  1008.4  100.0  10.0\n",
      "28502 2025-01-16 02:00:00  MONTE CASEROS AERO  24.3  69.5  1008.0  105.0   9.0\n",
      "28503 2025-01-16 03:00:00  MONTE CASEROS AERO  24.2  69.5  1007.8   90.0  11.0\n",
      "28504 2025-01-16 04:00:00  MONTE CASEROS AERO  23.8  73.0  1007.8   90.0  10.0\n",
      "28505 2025-01-16 05:00:00  MONTE CASEROS AERO  22.9  81.5  1008.1   80.0   8.0\n",
      "28506 2025-01-16 06:00:00  MONTE CASEROS AERO  22.1  84.0  1008.4  100.0   7.0\n",
      "28507 2025-01-16 07:00:00  MONTE CASEROS AERO  22.9  79.5  1008.9   90.0  11.0\n",
      "28508 2025-01-16 08:00:00  MONTE CASEROS AERO  24.9  71.5  1009.6   80.0  14.0\n",
      "28509 2025-01-16 09:00:00  MONTE CASEROS AERO  26.4  67.5  1010.0   70.0  12.0\n",
      "28510 2025-01-16 10:00:00  MONTE CASEROS AERO  28.7  60.0  1010.1   70.0  14.0\n",
      "28511 2025-01-16 11:00:00  MONTE CASEROS AERO  30.3  54.5  1010.0   80.0   7.5\n",
      "28512 2025-01-16 12:00:00  MONTE CASEROS AERO  32.3  43.5  1009.5   95.0  14.0\n",
      "28513 2025-01-16 13:00:00  MONTE CASEROS AERO  33.5  40.0  1009.0  105.0  14.0\n",
      "28514 2025-01-16 14:00:00  MONTE CASEROS AERO  35.0  34.0  1008.4  135.0  15.0\n",
      "28515 2025-01-16 15:00:00  MONTE CASEROS AERO  36.0  33.0  1007.5  145.0  16.0\n",
      "28516 2025-01-16 16:00:00  MONTE CASEROS AERO  36.6  30.0  1006.8  145.0  16.0\n",
      "28517 2025-01-16 17:00:00  MONTE CASEROS AERO  36.5  27.0  1006.4   95.0  16.0\n",
      "28518 2025-01-16 18:00:00  MONTE CASEROS AERO  36.3  28.0  1006.2  125.0  14.0\n",
      "28519 2025-01-16 19:00:00  MONTE CASEROS AERO  35.3  30.0  1006.2   95.0  13.0\n",
      "28520 2025-01-16 20:00:00  MONTE CASEROS AERO  33.3  38.5  1006.7   95.0   9.0\n",
      "28521 2025-01-16 21:00:00  MONTE CASEROS AERO  30.7  45.0  1007.0  250.0   7.5\n",
      "28522 2025-01-16 22:00:00  MONTE CASEROS AERO  30.0  50.0  1008.0   80.0  15.0\n",
      "28523 2025-01-16 23:00:00  MONTE CASEROS AERO  28.2  57.0  1008.6   95.0   8.0\n",
      "\n",
      "=== Estación: ITUZAINGO ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA     NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "12254 2024-10-24 06:00:00  ITUZAINGO  20.5  94.5  1006.6   25.0   3.5\n",
      "12255 2024-10-24 09:00:00  ITUZAINGO  25.6  75.5  1006.4  250.0  13.0\n",
      "12256 2024-10-24 10:00:00  ITUZAINGO  28.1  66.0  1006.1   50.0  16.0\n",
      "12257 2024-10-24 11:00:00  ITUZAINGO  28.8  63.0  1006.0   50.0  13.0\n",
      "12258 2024-10-24 12:00:00  ITUZAINGO  30.0  60.5  1005.4  250.0  12.0\n",
      "12259 2024-10-24 13:00:00  ITUZAINGO  30.2  58.5  1005.4  250.0  11.0\n",
      "12260 2024-10-24 14:00:00  ITUZAINGO  31.4  56.0  1004.0  230.0  10.0\n",
      "12261 2024-10-24 15:00:00  ITUZAINGO  31.3  54.0  1003.2  270.0  10.0\n",
      "12262 2024-10-24 16:00:00  ITUZAINGO  30.9  56.0  1003.1  250.0  10.0\n",
      "12263 2024-10-24 17:00:00  ITUZAINGO  30.4  58.0  1002.8  270.0  10.0\n",
      "12264 2024-10-24 18:00:00  ITUZAINGO  29.0  64.5  1002.9  250.0  10.0\n",
      "12265 2024-10-24 19:00:00  ITUZAINGO  26.2  80.0  1002.6   70.0   4.5\n",
      "12266 2024-10-24 20:00:00  ITUZAINGO  25.2  81.5  1003.1  250.0   7.5\n",
      "12267 2024-10-24 21:00:00  ITUZAINGO  24.1  85.5  1004.2  250.0   6.5\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA     NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "12828 2024-12-04 06:00:00  ITUZAINGO  18.7  91.5  1008.5   70.0   4.5\n",
      "12829 2024-12-04 09:00:00  ITUZAINGO  24.7  74.5  1009.4   95.0  16.0\n",
      "12830 2024-12-04 10:00:00  ITUZAINGO  25.6  69.0  1009.6  250.0  16.0\n",
      "12831 2024-12-04 11:00:00  ITUZAINGO  27.3  63.0  1009.8   95.0  17.0\n",
      "12832 2024-12-04 12:00:00  ITUZAINGO  26.8  66.5  1009.4   95.0  15.0\n",
      "12833 2024-12-04 13:00:00  ITUZAINGO  27.8  65.0  1009.6  115.0  15.0\n",
      "12834 2024-12-04 14:00:00  ITUZAINGO  28.5  61.5  1008.7  140.0  13.0\n",
      "12835 2024-12-04 15:00:00  ITUZAINGO  28.8  61.0  1008.4   95.0  12.0\n",
      "12836 2024-12-04 16:00:00  ITUZAINGO  28.6  59.0  1007.3  250.0  14.0\n",
      "12837 2024-12-04 17:00:00  ITUZAINGO  28.0  58.5  1007.0  115.0  13.0\n",
      "12838 2024-12-04 18:00:00  ITUZAINGO  27.2  62.0  1006.8  250.0  11.0\n",
      "12839 2024-12-04 19:00:00  ITUZAINGO  25.8  63.5  1006.7   95.0  14.0\n",
      "12840 2024-12-04 20:00:00  ITUZAINGO  24.6  74.5  1006.8  115.0  10.0\n",
      "12841 2024-12-04 21:00:00  ITUZAINGO  24.1  75.5  1007.0   95.0  13.0\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA     NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "12926 2024-12-11 06:00:00  ITUZAINGO  19.8  95.5  1009.6  160.0   9.0\n",
      "12927 2024-12-11 09:00:00  ITUZAINGO  24.4  82.5  1010.2  100.0   6.0\n",
      "12928 2024-12-11 10:00:00  ITUZAINGO  26.6  75.0  1011.0   95.0   9.0\n",
      "12929 2024-12-11 11:00:00  ITUZAINGO  28.6  67.0  1010.5   95.0  10.0\n",
      "12930 2024-12-11 12:00:00  ITUZAINGO  28.6  67.0  1010.0   95.0  11.0\n",
      "12931 2024-12-11 13:00:00  ITUZAINGO  29.6  66.0  1009.4  140.0  11.0\n",
      "12932 2024-12-11 14:00:00  ITUZAINGO  30.3  62.5  1008.8  115.0  10.0\n",
      "12933 2024-12-11 15:00:00  ITUZAINGO  30.6  58.0  1008.2   95.0  11.0\n",
      "12934 2024-12-11 16:00:00  ITUZAINGO  30.8  58.0  1007.4  250.0  14.0\n",
      "12935 2024-12-11 17:00:00  ITUZAINGO  30.3  60.0  1007.0   95.0  11.0\n",
      "12936 2024-12-11 18:00:00  ITUZAINGO  29.2  64.5  1006.4   95.0   9.0\n",
      "12937 2024-12-11 19:00:00  ITUZAINGO  27.6  71.0  1006.2   95.0   8.0\n",
      "12938 2024-12-11 20:00:00  ITUZAINGO  26.6  75.5  1006.6  180.0   5.5\n",
      "12939 2024-12-11 21:00:00  ITUZAINGO  25.2  79.5  1007.3  180.0   7.5\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA     NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "13430 2025-01-16 06:00:00  ITUZAINGO  22.8  92.0  1007.2  230.0  10.0\n",
      "13431 2025-01-16 09:00:00  ITUZAINGO  26.5  80.0  1008.0  230.0   9.0\n",
      "13432 2025-01-16 10:00:00  ITUZAINGO  29.9  67.5  1008.0  205.0   9.0\n",
      "13433 2025-01-16 11:00:00  ITUZAINGO  32.1  61.0  1007.8   95.0  10.0\n",
      "13434 2025-01-16 12:00:00  ITUZAINGO  34.3  55.0  1007.4   70.0   9.0\n",
      "13435 2025-01-16 13:00:00  ITUZAINGO  33.8  57.0  1006.8  160.0   9.0\n",
      "13436 2025-01-16 14:00:00  ITUZAINGO  34.2  53.5  1006.2  160.0   6.5\n",
      "13437 2025-01-16 15:00:00  ITUZAINGO  35.5  51.5  1005.8   95.0   9.0\n",
      "13438 2025-01-16 16:00:00  ITUZAINGO  35.8  46.0  1005.4  250.0  11.0\n",
      "13439 2025-01-16 17:00:00  ITUZAINGO  36.4  42.0  1004.6  115.0  10.0\n",
      "13440 2025-01-16 18:00:00  ITUZAINGO  35.9  47.0  1004.8  140.0  10.0\n",
      "13441 2025-01-16 19:00:00  ITUZAINGO  34.0  52.5  1004.6  140.0   9.0\n",
      "13442 2025-01-16 20:00:00  ITUZAINGO  30.2  72.0  1005.2   70.0   4.5\n",
      "13443 2025-01-16 21:00:00  ITUZAINGO  27.8  79.5  1005.6    0.0   0.0\n",
      "\n",
      "=== Estación: MERCEDES AERO (CTES) ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "18508 2024-10-24 06:00:00  MERCEDES AERO (CTES)  19.0  92.0  1006.6   35.0   4.5\n",
      "18509 2024-10-24 07:00:00  MERCEDES AERO (CTES)  19.5  91.0  1006.8  160.0   7.5\n",
      "18510 2024-10-24 08:00:00  MERCEDES AERO (CTES)  22.6  82.5  1007.2  150.0  11.0\n",
      "18511 2024-10-24 09:00:00  MERCEDES AERO (CTES)  24.9  72.5  1007.4  125.0  14.0\n",
      "18512 2024-10-24 10:00:00  MERCEDES AERO (CTES)  27.2  63.0  1007.2  110.0  13.0\n",
      "18513 2024-10-24 11:00:00  MERCEDES AERO (CTES)  28.7  54.5  1006.8  140.0  16.5\n",
      "18514 2024-10-24 12:00:00  MERCEDES AERO (CTES)  30.0  50.5  1006.4  275.0  13.5\n",
      "18515 2024-10-24 13:00:00  MERCEDES AERO (CTES)  30.4  49.5  1005.8  285.0  14.5\n",
      "18516 2024-10-24 14:00:00  MERCEDES AERO (CTES)  31.5  46.0  1005.3  310.0  17.5\n",
      "18517 2024-10-24 15:00:00  MERCEDES AERO (CTES)  31.4  44.0  1004.4  305.0  16.5\n",
      "18518 2024-10-24 16:00:00  MERCEDES AERO (CTES)  31.6  43.0  1003.5  265.0  17.5\n",
      "18519 2024-10-24 17:00:00  MERCEDES AERO (CTES)  31.6  41.5  1003.0  290.0  16.5\n",
      "18520 2024-10-24 18:00:00  MERCEDES AERO (CTES)  30.4  47.0  1003.3  295.0  18.0\n",
      "18521 2024-10-24 19:00:00  MERCEDES AERO (CTES)  28.4  57.5  1004.2  280.0  23.0\n",
      "18522 2024-10-24 20:00:00  MERCEDES AERO (CTES)  25.8  65.0  1005.4  110.0  22.0\n",
      "18523 2024-10-24 21:00:00  MERCEDES AERO (CTES)  24.9  65.5  1006.4  100.0  20.5\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "19164 2024-12-04 06:00:00  MERCEDES AERO (CTES)  15.4  82.0  1011.7   80.0   8.0\n",
      "19165 2024-12-04 07:00:00  MERCEDES AERO (CTES)  17.2  77.5  1011.8  105.0   9.0\n",
      "19166 2024-12-04 08:00:00  MERCEDES AERO (CTES)  20.6  67.0  1012.1   85.0  14.0\n",
      "19167 2024-12-04 09:00:00  MERCEDES AERO (CTES)  23.0  55.0  1012.4   90.0  13.0\n",
      "19168 2024-12-04 10:00:00  MERCEDES AERO (CTES)  25.0  52.0  1012.2   80.0  16.0\n",
      "19169 2024-12-04 11:00:00  MERCEDES AERO (CTES)  26.6  49.0  1011.9   95.0  19.0\n",
      "19170 2024-12-04 12:00:00  MERCEDES AERO (CTES)  27.5  46.5  1011.4  105.0  19.5\n",
      "19171 2024-12-04 13:00:00  MERCEDES AERO (CTES)  28.7  46.0  1010.8   90.0  23.0\n",
      "19172 2024-12-04 14:00:00  MERCEDES AERO (CTES)  28.8  46.5  1010.2   90.0  23.0\n",
      "19173 2024-12-04 15:00:00  MERCEDES AERO (CTES)  29.0  47.5  1009.6   80.0  19.5\n",
      "19174 2024-12-04 16:00:00  MERCEDES AERO (CTES)  28.7  47.5  1008.8   80.0  18.0\n",
      "19175 2024-12-04 17:00:00  MERCEDES AERO (CTES)  28.0  49.5  1008.2   90.0  17.5\n",
      "19176 2024-12-04 18:00:00  MERCEDES AERO (CTES)  27.2  54.5  1008.2  105.0  13.0\n",
      "19177 2024-12-04 19:00:00  MERCEDES AERO (CTES)  25.0  65.5  1008.0   95.0  14.0\n",
      "19178 2024-12-04 20:00:00  MERCEDES AERO (CTES)  23.8  68.0  1008.3   95.0  12.0\n",
      "19179 2024-12-04 21:00:00  MERCEDES AERO (CTES)  23.4  70.5  1008.2   95.0  10.0\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "19276 2024-12-11 06:00:00  MERCEDES AERO (CTES)  17.3  86.5  1012.0  115.0   7.0\n",
      "19277 2024-12-11 07:00:00  MERCEDES AERO (CTES)  19.2  81.5  1012.2  100.0  11.0\n",
      "19278 2024-12-11 08:00:00  MERCEDES AERO (CTES)  21.4  85.5  1012.8   80.0  10.0\n",
      "19279 2024-12-11 09:00:00  MERCEDES AERO (CTES)  23.1  75.0  1012.8   70.0  11.0\n",
      "19280 2024-12-11 10:00:00  MERCEDES AERO (CTES)  25.2  67.0  1012.6   80.0  12.0\n",
      "19281 2024-12-11 11:00:00  MERCEDES AERO (CTES)  27.1  59.0  1012.2  100.0  11.0\n",
      "19282 2024-12-11 12:00:00  MERCEDES AERO (CTES)  28.7  47.5  1012.0  140.0  15.0\n",
      "19283 2024-12-11 13:00:00  MERCEDES AERO (CTES)  29.6  48.0  1011.4  105.0  12.0\n",
      "19284 2024-12-11 14:00:00  MERCEDES AERO (CTES)  30.0  46.5  1010.6  100.0  10.0\n",
      "19285 2024-12-11 15:00:00  MERCEDES AERO (CTES)  30.7  44.0  1009.9   95.0  10.0\n",
      "19286 2024-12-11 16:00:00  MERCEDES AERO (CTES)  30.2  42.5  1009.3   80.0  13.0\n",
      "19287 2024-12-11 17:00:00  MERCEDES AERO (CTES)  30.2  42.0  1008.4  105.0  11.0\n",
      "19288 2024-12-11 18:00:00  MERCEDES AERO (CTES)  30.0  43.0  1007.7   85.0  13.0\n",
      "19289 2024-12-11 19:00:00  MERCEDES AERO (CTES)  28.2  49.0  1007.6   90.0  10.0\n",
      "19290 2024-12-11 20:00:00  MERCEDES AERO (CTES)  25.8  64.5  1007.8  105.0   6.0\n",
      "19291 2024-12-11 21:00:00  MERCEDES AERO (CTES)  24.4  63.5  1008.2   85.0   9.0\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA                NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "19852 2025-01-16 06:00:00  MERCEDES AERO (CTES)  21.7  86.0  1008.1   80.0   6.5\n",
      "19853 2025-01-16 07:00:00  MERCEDES AERO (CTES)  22.0  86.0  1008.5   80.0   6.5\n",
      "19854 2025-01-16 08:00:00  MERCEDES AERO (CTES)  23.6  80.0  1009.1   50.0   8.0\n",
      "19855 2025-01-16 09:00:00  MERCEDES AERO (CTES)  25.9  71.5  1009.4   45.0   9.5\n",
      "19856 2025-01-16 10:00:00  MERCEDES AERO (CTES)  29.9  54.0  1009.6  195.0  10.0\n",
      "19857 2025-01-16 11:00:00  MERCEDES AERO (CTES)  32.9  45.0  1009.3  105.0   8.5\n",
      "19858 2025-01-16 12:00:00  MERCEDES AERO (CTES)  34.0  39.5  1009.0  100.0   9.0\n",
      "19859 2025-01-16 13:00:00  MERCEDES AERO (CTES)  35.3  36.0  1008.4   80.0  10.0\n",
      "19860 2025-01-16 14:00:00  MERCEDES AERO (CTES)  36.8  32.0  1007.7  240.0  12.0\n",
      "19861 2025-01-16 15:00:00  MERCEDES AERO (CTES)  37.0  30.0  1006.9  115.0  10.5\n",
      "19862 2025-01-16 16:00:00  MERCEDES AERO (CTES)  37.7  25.0  1006.4  170.0  11.0\n",
      "19863 2025-01-16 17:00:00  MERCEDES AERO (CTES)  37.8  25.0  1005.8  115.0  11.0\n",
      "19864 2025-01-16 18:00:00  MERCEDES AERO (CTES)  37.0  26.0  1005.8  100.0  13.0\n",
      "19865 2025-01-16 19:00:00  MERCEDES AERO (CTES)  35.8  29.0  1005.8   95.0  12.0\n",
      "19866 2025-01-16 20:00:00  MERCEDES AERO (CTES)  32.2  43.5  1006.6   65.0  13.0\n",
      "19867 2025-01-16 21:00:00  MERCEDES AERO (CTES)  29.7  49.0  1007.3   55.0   6.5\n",
      "\n",
      "Resumen de verificación de imputaciones por estación:\n",
      "                  Estación  Total días faltantes  Días completos  Días con NaN\n",
      "0  PASO DE LOS LIBRES AERO                     4               4             0\n",
      "1          CORRIENTES AERO                     4               4             0\n",
      "2       MONTE CASEROS AERO                     4               4             0\n",
      "3                ITUZAINGO                     4               4             0\n",
      "4     MERCEDES AERO (CTES)                     4               4             0\n"
     ]
    }
   ],
   "source": [
    "# Carpeta con los archivos de días faltantes\n",
    "FALTANTES_DIR = Path(\"../data/faltantes\")  # Ajustar al directorio correcto\n",
    "variables_objetivo = ['TEMP', 'HUM', 'PNM', 'DD', 'FF']\n",
    "\n",
    "# Función para leer días faltantes de un archivo\n",
    "def leer_dias_faltantes(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    fechas = [line.strip() for line in lines if line.strip() and line.strip()[0].isdigit()]\n",
    "    return pd.to_datetime(fechas).date\n",
    "\n",
    "# Recorrer todos los archivos .txt de días faltantes\n",
    "faltantes_files = list(FALTANTES_DIR.glob(\"*.txt\"))\n",
    "\n",
    "resumen_resultados = []\n",
    "\n",
    "for file_path in faltantes_files:\n",
    "    estacion = file_path.stem.replace(\"dias_faltantes_\", \"\").replace(\"_\", \" \").upper()\n",
    "    dias_faltantes = leer_dias_faltantes(file_path)\n",
    "    \n",
    "    print(f\"\\n=== Estación: {estacion} ===\")\n",
    "    resultados_estacion = {\"Estación\": estacion, \"Total días faltantes\": len(dias_faltantes), \"Días completos\": 0, \"Días con NaN\": 0}\n",
    "    \n",
    "    for fecha in dias_faltantes:\n",
    "        subset_original = df_horario_completo[(df_horario_completo['NOMBRE'].str.upper() == estacion) & (df_horario_completo['FECHA'] == fecha)]\n",
    "        subset_imputado = df_interp[(df_interp['NOMBRE'].str.upper() == estacion) & (df_interp['FECHA'] == fecha)]\n",
    "        \n",
    "        if subset_imputado[variables_objetivo].isnull().any().any():\n",
    "            resultados_estacion[\"Días con NaN\"] += 1\n",
    "            print(f\"\\nFecha {fecha} aún con NaN\")\n",
    "        else:\n",
    "            resultados_estacion[\"Días completos\"] += 1\n",
    "            print(f\"\\nFecha {fecha} imputada correctamente\")\n",
    "        \n",
    "        # Comparar antes y después\n",
    "        if not subset_imputado.empty:\n",
    "            print(\"\\n--- Antes (Original con NaN) ---\")\n",
    "            print(subset_original[['FECHA_HORA', 'NOMBRE'] + variables_objetivo])\n",
    "            print(\"\\n--- Después (Imputado) ---\")\n",
    "            print(subset_imputado[['FECHA_HORA', 'NOMBRE'] + variables_objetivo])\n",
    "    \n",
    "    resumen_resultados.append(resultados_estacion)\n",
    "\n",
    "# Mostrar resumen final\n",
    "df_resumen = pd.DataFrame(resumen_resultados)\n",
    "print(\"\\nResumen de verificación de imputaciones por estación:\")\n",
    "print(df_resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a775e-65d6-4257-87bd-2ca94a7ec61b",
   "metadata": {},
   "source": [
    "# Verificación de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "505c7ad1-8fc5-4237-bb4f-73822d928246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron fechas faltantes después de la imputación.\n",
      "\n",
      "Ejemplo de fechas faltantes:\n",
      "Empty DataFrame\n",
      "Columns: [NOMBRE, FECHA]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame reducido solo con días únicos por estación\n",
    "df_fechas = df_interp[['FECHA', 'NOMBRE']].drop_duplicates()\n",
    "\n",
    "# Generar rango completo de fechas\n",
    "fechas_totales = pd.date_range(start=df_fechas['FECHA'].min(), end=df_fechas['FECHA'].max(), freq='D')\n",
    "\n",
    "# Estaciones\n",
    "estaciones = df_fechas['NOMBRE'].unique()\n",
    "# Crear todas las combinaciones posibles (fecha, estación)\n",
    "index_completo = pd.MultiIndex.from_product([fechas_totales, estaciones], names=['FECHA', 'NOMBRE'])\n",
    "\n",
    "# Reindexar\n",
    "df_check = df_fechas.set_index(['FECHA', 'NOMBRE']).reindex(index_completo).reset_index()\n",
    "\n",
    "# Verificar faltantes\n",
    "faltantes = df_check[df_check.isnull().any(axis=1)][['NOMBRE', 'FECHA']]\n",
    "\n",
    "# Exportar resultados\n",
    "if not faltantes.empty:\n",
    "    archivo_faltantes_final = PLATA_DIR / \"fechas_faltantes_post_imputacion.txt\"\n",
    "    faltantes.to_csv(archivo_faltantes_final, index=False, sep='\\t')\n",
    "    print(f\"Fechas faltantes exportadas a: {archivo_faltantes_final}\")\n",
    "else:\n",
    "    print(\"No se encontraron fechas faltantes después de la imputación.\")\n",
    "\n",
    "# Vista rápida\n",
    "print(\"\\nEjemplo de fechas faltantes:\")\n",
    "print(faltantes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa51e0-6e02-4cda-820c-d2c6f8b5c2eb",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "En este notebook hemos completado el proceso de **enriquecimiento de la Capa Plata**.\n",
    "\n",
    "Se garantiza:\n",
    "- **Datos horarios completos** por estación para el período de análisis.\n",
    "- **Tratamiento adecuado de valores faltantes**, aplicando imputaciones coherentes con el comportamiento histórico de cada estación.\n",
    "- Generación de un **dataset final imputado** que sirve como base para análisis avanzados (clustering, PCA, detección de eventos).\n",
    "\n",
    "Con esta preparación, los datos están listos para las tareas de **minería de datos y categorización**, que abordaremos en la clase siguiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
