{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Ingesta y Capa Bronce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a3d2d",
   "metadata": {},
   "source": [
    "En esta notebook se inicia la construcción del pipeline de datos meteorológicos, trabajando con los archivos crudos provistos por el SMN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573fb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importación de librerías completada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Importación de librerías completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## Configuración de paths y carpetas del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069e436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciación de carpetas del proyecto completada.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "for path in [BRONCE_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Iniciación de carpetas del proyecto completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## Lectura del archivo de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones cargadas: 117\n",
      "Cantidad de provincias: 26\n",
      "Provincias disponibles: ['ANTARTIDA' 'BUENOS AIRES' 'CAPITAL FEDERAL' 'CATAMARCA' '' 'CHACO'\n",
      " 'CHUBUT' 'CORDOBA' 'CORRIENTES' 'ENTRE RIOS' 'FORMOSA' 'JUJUY' 'LA PAMPA'\n",
      " 'LA RIOJA' 'MENDOZA' 'MISIONES' 'NEUQUEN' 'RIO NEGRO' 'SALTA' 'SAN JUAN'\n",
      " 'SAN LUIS' 'SANTA CRUZ' 'SANTA FE' 'SANTIAGO DEL ESTERO'\n",
      " 'TIERRA DEL FUEGO' 'TUCUMAN']\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "archivo_estaciones = RAW_DIR / 'estaciones' / 'estaciones_smn.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_estaciones, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()[2:]\n",
    "\n",
    "# Expresión regular para extraer campos:\n",
    "pattern = re.compile(\n",
    "    r\"^(?P<nombre>.+?)\\s{2,}(?P<provincia>.+?)\\s{2,}(?P<lat_gr>-?\\d+)\\s+(?P<lat_min>\\d+)\\s+(?P<lon_gr>-?\\d+)\\s+(?P<lon_min>\\d+)\\s+(?P<altura_m>\\d+)\\s+(?P<numero>\\d+)\\s+(?P<numero_oaci>\\S+)\\s*$\"\n",
    ")\n",
    "\n",
    "# Extraer los datos\n",
    "data = []\n",
    "for line in lines:\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        data.append(match.groupdict())\n",
    "\n",
    "# Crear DataFrame\n",
    "df_estaciones = pd.DataFrame(data)\n",
    "\n",
    "# Conversión de tipos\n",
    "df_estaciones[['lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero']] = df_estaciones[[\n",
    "    'lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero'\n",
    "]].apply(pd.to_numeric)\n",
    "\n",
    "# Cargar las provincias\n",
    "provincias_unicas = df_estaciones['provincia'].str.strip().str.upper().unique()\n",
    "\n",
    "# Imprimir la cantidad de estaciones registradas\n",
    "print(\"Estaciones cargadas:\", len(df_estaciones))\n",
    "\n",
    "# Imprimir la cantidad de provincias registradas\n",
    "print(\"Cantidad de provincias:\", len(provincias_unicas))\n",
    "\n",
    "# Imprimir las provincias\n",
    "print(\"Provincias disponibles:\", provincias_unicas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## Selección de estaciones. \n",
    "\n",
    "### Para el desarrollo del trabajo se utilizarán las estaciones ubicadas en la provincia de Misiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355e73a4-ae19-4a13-9709-93f131a03792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>provincia</th>\n",
       "      <th>numero</th>\n",
       "      <th>numero_oaci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CORRIENTES AERO</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>87166</td>\n",
       "      <td>SARC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ITUZAINGO</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>87173</td>\n",
       "      <td>SARO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>MERCEDES AERO (CTES)</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>87281</td>\n",
       "      <td>SATM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>MONTE CASEROS AERO</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>87393</td>\n",
       "      <td>SARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PASO DE LOS LIBRES AERO</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>87289</td>\n",
       "      <td>SARL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nombre   provincia  numero numero_oaci\n",
       "52          CORRIENTES AERO  CORRIENTES   87166        SARC\n",
       "53                ITUZAINGO  CORRIENTES   87173        SARO\n",
       "54     MERCEDES AERO (CTES)  CORRIENTES   87281        SATM\n",
       "55       MONTE CASEROS AERO  CORRIENTES   87393        SARM\n",
       "56  PASO DE LOS LIBRES AERO  CORRIENTES   87289        SARL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingresar el nombre de la provincia con la que se va a trabajar\n",
    "provincia = 'CORRIENTES'\n",
    "\n",
    "df_provincia = df_estaciones[df_estaciones['provincia'].str.upper() == provincia]\n",
    "df_provincia[['nombre', 'provincia', 'numero', 'numero_oaci']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a92af-1e2b-4851-8929-6e6a8476500c",
   "metadata": {},
   "source": [
    "## Filtrar las estaciones que correspondan a la provincia seleccionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac45e6ae-4c6a-422b-80e2-3125b1a5f206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FECHA HORA TEMP HUM    PNM  DD FF                  NOMBRE\n",
      "31052025    0  9.2  87 1021.7 120  7         CORRIENTES AERO\n",
      "31052025    1  9.1  92 1021.4 110  6         CORRIENTES AERO\n",
      "31052025    2  8.0  95 1021.3 120  4         CORRIENTES AERO\n",
      "31052025    3  7.3  96 1021.4 140  6         CORRIENTES AERO\n",
      "31052025    4  7.0  95 1021.2 140  6         CORRIENTES AERO\n",
      "31052025    5  6.6  95 1021.1   0  0         CORRIENTES AERO\n",
      "31052025    6  6.1  99 1021.4   0  0         CORRIENTES AERO\n",
      "31052025    7  6.2  97 1021.8 140  4         CORRIENTES AERO\n",
      "31052025    8  6.1  99 1022.3 130  4         CORRIENTES AERO\n",
      "31052025    9  8.9  99 1022.9 140  4         CORRIENTES AERO\n",
      "31052025   10 12.1  85 1023.3  70  9         CORRIENTES AERO\n",
      "31052025   11 14.3  73 1023.9  80  6         CORRIENTES AERO\n",
      "31052025   12 15.5  65 1023.3 250  6         CORRIENTES AERO\n",
      "31052025   13 16.4  61 1022.9 320  9         CORRIENTES AERO\n",
      "31052025   14 15.9  56 1022.4 230 11         CORRIENTES AERO\n",
      "31052025   15 16.1  57 1022.0 200 11         CORRIENTES AERO\n",
      "31052025   16 16.0  58 1021.7 180  7         CORRIENTES AERO\n",
      "31052025   17 15.5  60 1022.0 200 11         CORRIENTES AERO\n",
      "31052025   18 14.9  68 1022.3 160  9         CORRIENTES AERO\n",
      "31052025   19 13.9  74 1022.9 160  7         CORRIENTES AERO\n",
      "31052025   20 12.0  80 1023.3 140  9         CORRIENTES AERO\n",
      "31052025   21 11.2  85 1023.6 140 11         CORRIENTES AERO\n",
      "31052025   22 10.8  88 1024.0 160  7         CORRIENTES AERO\n",
      "31052025   23 10.5  89 1023.9 150  7         CORRIENTES AERO\n",
      "31052025    6  9.2  97 1021.7  50  9               ITUZAINGO\n",
      "31052025    9 10.2  95 1021.7  50  6               ITUZAINGO\n",
      "31052025   10 12.6  91 1022.3  50  6               ITUZAINGO\n",
      "31052025   11 15.0  77 1022.1 140  6               ITUZAINGO\n",
      "31052025   12 16.6  64 1021.8 140  7               ITUZAINGO\n",
      "31052025   13 16.4  62 1021.3 140  9               ITUZAINGO\n",
      "31052025   14 16.4  66 1021.8 140  9               ITUZAINGO\n",
      "31052025   15 15.0  69 1021.8 180  6               ITUZAINGO\n",
      "31052025   16 14.8  68 1021.0   0  0               ITUZAINGO\n",
      "31052025   17 13.8  80 1021.7   0  0               ITUZAINGO\n",
      "31052025   18 13.2  80 1021.4 140  6               ITUZAINGO\n",
      "31052025   19 12.8  82 1022.5 180 11               ITUZAINGO\n",
      "31052025   20 12.0  83 1022.9 180  9               ITUZAINGO\n",
      "31052025   21 10.6  95 1022.7   0  0               ITUZAINGO\n",
      "31052025    6  7.6  94 1021.9  20  4    MERCEDES AERO (CTES)\n",
      "31052025    7  7.0  94 1022.0  20  4    MERCEDES AERO (CTES)\n",
      "31052025    8  6.4  94 1022.7  20  4    MERCEDES AERO (CTES)\n",
      "31052025    9  8.6  95 1023.2  50  4    MERCEDES AERO (CTES)\n",
      "31052025   10 12.2  79 1023.7  50  2    MERCEDES AERO (CTES)\n",
      "31052025   11 14.8  66 1024.0  50  4    MERCEDES AERO (CTES)\n",
      "31052025   12 14.4  62 1023.9 140  6    MERCEDES AERO (CTES)\n",
      "31052025   13 15.0  60 1023.2 250  4    MERCEDES AERO (CTES)\n",
      "31052025   14 15.2  55 1022.4 140  9    MERCEDES AERO (CTES)\n",
      "31052025   15 16.4  55 1021.8 230  9    MERCEDES AERO (CTES)\n",
      "31052025   16 16.0  58 1021.9 180  9    MERCEDES AERO (CTES)\n",
      "31052025   17 14.6  64 1022.1 160  9    MERCEDES AERO (CTES)\n",
      "31052025   18 13.8  72 1022.7 180  4    MERCEDES AERO (CTES)\n",
      "31052025   19 13.4  77 1023.2   0  0    MERCEDES AERO (CTES)\n",
      "31052025   20 13.0  71 1023.8 180  4    MERCEDES AERO (CTES)\n",
      "31052025   21 12.0  79 1024.2 180  4    MERCEDES AERO (CTES)\n",
      "31052025    0  7.0  97 1022.4  20  6      MONTE CASEROS AERO\n",
      "31052025    1  8.0  95 1022.4  50  9      MONTE CASEROS AERO\n",
      "31052025    2  6.6  97 1022.5 180  4      MONTE CASEROS AERO\n",
      "31052025    3  6.4  97 1022.2  50  4      MONTE CASEROS AERO\n",
      "31052025    4  6.0  97 1022.4 180  7      MONTE CASEROS AERO\n",
      "31052025    5  6.4  94 1021.9 140  2      MONTE CASEROS AERO\n",
      "31052025    6  5.6  94 1022.0  90  2      MONTE CASEROS AERO\n",
      "31052025    7  5.0  99 1022.5  90  2      MONTE CASEROS AERO\n",
      "31052025    8  4.6  99 1022.9 160  2      MONTE CASEROS AERO\n",
      "31052025    9  5.9  97 1023.4 110  2      MONTE CASEROS AERO\n",
      "31052025   10 11.2  88 1024.0 140  2      MONTE CASEROS AERO\n",
      "31052025   11 13.2  77 1024.3 290  4      MONTE CASEROS AERO\n",
      "31052025   12 15.6  61 1023.7 250  6      MONTE CASEROS AERO\n",
      "31052025   13 15.2  61 1023.2 250  6      MONTE CASEROS AERO\n",
      "31052025   14 15.2  65 1022.5 230  6      MONTE CASEROS AERO\n",
      "31052025   15 15.2  61 1022.2 250 11      MONTE CASEROS AERO\n",
      "31052025   16 15.4  57 1022.2 180  6      MONTE CASEROS AERO\n",
      "31052025   17 15.4  56 1022.2 270  2      MONTE CASEROS AERO\n",
      "31052025   18 14.0  67 1022.5 230  4      MONTE CASEROS AERO\n",
      "31052025   19 11.4  85 1023.4 250  6      MONTE CASEROS AERO\n",
      "31052025   20  9.8  92 1024.1 200  6      MONTE CASEROS AERO\n",
      "31052025   21  9.0  95 1024.6 180  2      MONTE CASEROS AERO\n",
      "31052025   22  8.4  95 1024.6 140  2      MONTE CASEROS AERO\n",
      "31052025   23  7.8  97 1024.6 360  2      MONTE CASEROS AERO\n",
      "31052025    0  7.2  95 1022.7   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    1  6.9  99 1022.5   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    2  7.0  97 1022.2   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    3  6.4  97 1022.3   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    4  6.6  99 1022.2   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    5  7.3  96 1022.3   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    6  7.1  95 1022.3   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    7  7.0  99 1022.6   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    8  6.6  97 1023.1   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025    9  8.6  92 1023.4   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   10 12.0  88 1024.0   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   11 13.2  77 1024.3   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   12 13.9  68 1023.9 180  7 PASO DE LOS LIBRES AERO\n",
      "31052025   13 14.4  64 1023.3 230  6 PASO DE LOS LIBRES AERO\n",
      "31052025   14 16.2  62 1022.4 270  4 PASO DE LOS LIBRES AERO\n",
      "31052025   15 15.2  65 1022.2 200  4 PASO DE LOS LIBRES AERO\n",
      "31052025   16 15.2  65 1022.3 230  6 PASO DE LOS LIBRES AERO\n",
      "31052025   17 15.0  69 1022.3 270  6 PASO DE LOS LIBRES AERO\n",
      "31052025   18 13.4  82 1022.9   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   19 13.4  82 1022.9   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   20 12.6  87 1024.2   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   21 12.4  91 1024.6   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   22 11.1  95 1024.9   0  0 PASO DE LOS LIBRES AERO\n",
      "31052025   23 10.8  92 1024.9   0  0 PASO DE LOS LIBRES AERO\n",
      "\n",
      "Columnas: ['FECHA', 'HORA', 'TEMP', 'HUM', 'PNM', 'DD', 'FF', 'NOMBRE']\n",
      "Tipos de dato:\n",
      "FECHA      object\n",
      "HORA        Int64\n",
      "TEMP      float64\n",
      "HUM         int64\n",
      "PNM       float64\n",
      "DD          Int64\n",
      "FF          Int64\n",
      "NOMBRE     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Se selecciona una fecha para visualizar los datos\n",
    "archivo_dato = RAW_DIR / 'datohorario' /  '_procesados' / 'datohorario20250531.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_dato, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Detectar columnas separadas por múltiples espacios\n",
    "columnas = re.split(r\"\\s{2,}\", lines[0].strip())\n",
    "\n",
    "# Leer datos\n",
    "data = [\n",
    "    re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "    for line in lines[1:]\n",
    "    if len(line.strip()) > 0 and not line.isspace()\n",
    "]\n",
    "\n",
    "# Crear DataFrame con columnas originales\n",
    "df_dato = pd.DataFrame(data, columns=columnas)\n",
    "df_dato.columns = df_dato.columns.str.strip()\n",
    "df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "# Filtrar por estaciones\n",
    "nombres_provincia = df_provincia[\"nombre\"].str.strip().unique()\n",
    "df_provincia_dia = df_dato[df_dato[\"NOMBRE\"].isin(nombres_provincia)]\n",
    "\n",
    "# Crear copia y convertir tipos SOLO para impresión de tipos correctos\n",
    "df_tipos = df_provincia_dia.copy()\n",
    "df_tipos[\"FECHA\"] = pd.to_datetime(df_tipos[\"FECHA\"], format=\"%d%m%Y\", errors=\"coerce\").dt.date\n",
    "df_tipos[\"HORA\"] = pd.to_numeric(df_tipos[\"HORA\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_tipos[\"TEMP\"] = pd.to_numeric(df_tipos[\"TEMP\"], errors=\"coerce\")\n",
    "df_tipos[\"HUM\"] = pd.to_numeric(df_tipos[\"HUM\"], errors=\"coerce\")\n",
    "df_tipos[\"PNM\"] = pd.to_numeric(df_tipos[\"PNM\"], errors=\"coerce\")\n",
    "df_tipos[\"DD\"] = pd.to_numeric(df_tipos[\"DD\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_tipos[\"FF\"] = pd.to_numeric(df_tipos[\"FF\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Mostrar todos los resultados\n",
    "print(df_provincia_dia.to_string(index=False))\n",
    "print()\n",
    "print(\"Columnas:\", df_dato.columns.tolist())\n",
    "print(\"Tipos de dato:\")\n",
    "print(df_tipos.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832851a",
   "metadata": {},
   "source": [
    "## Procesamiento por estación y por fecha (con limpieza y reporte resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5af8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado.\n",
      "Días procesados: 422\n",
      "Errores al procesar archivos: 0\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta de salida si no existe\n",
    "BRONCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Buscar todos los archivos datohorario disponibles\n",
    "archivos_datos = sorted(glob(str(RAW_DIR / \"datohorario\" / '_procesados' / \"datohorario*.txt\")))\n",
    "\n",
    "errores_globales = 0\n",
    "\n",
    "for archivo in archivos_datos:\n",
    "    try:\n",
    "        with open(archivo, encoding=\"latin1\") as f:\n",
    "            raw_lines = f.readlines()\n",
    "\n",
    "        header = raw_lines[0].strip()\n",
    "        columnas = re.split(r\"\\s{2,}\", header)\n",
    "\n",
    "        data = [\n",
    "            re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "            for line in raw_lines[1:]\n",
    "            if len(line.strip()) > 0 and not line.isspace()\n",
    "        ]\n",
    "\n",
    "        df_dato = pd.DataFrame(data, columns=columnas)\n",
    "        df_dato.columns = df_dato.columns.str.strip()\n",
    "        df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "        # Filtrar por estaciones según la provincia\n",
    "        df_provincia = df_dato[df_dato[\"NOMBRE\"].isin(nombres_provincia)]\n",
    "\n",
    "        # Obtener fecha\n",
    "        fecha = Path(archivo).stem.replace(\"datohorario\", \"\")\n",
    "\n",
    "        # Guardar archivos por estación\n",
    "        for nombre in nombres_provincia:\n",
    "            nombre_clean = nombre.lower().replace(\" \", \"_\")\n",
    "            df_estacion = df_provincia[df_provincia[\"NOMBRE\"] == nombre]\n",
    "\n",
    "            if not df_estacion.empty:\n",
    "                path_estacion = BRONCE_DIR / nombre_clean\n",
    "                path_estacion.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Archivos de salida\n",
    "                archivo_csv = path_estacion / f\"{fecha}.csv\"\n",
    "                df_estacion.to_csv(archivo_csv, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        errores_globales += 1\n",
    "        continue\n",
    "\n",
    "# Reporte final\n",
    "print(\"Proceso completado.\")\n",
    "print(f\"Días procesados: {len(archivos_datos)}\")\n",
    "print(f\"Errores al procesar archivos: {errores_globales}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9c0bc-09c9-4e51-9ef8-e975403b2422",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "En este notebook realizamos el proceso de **ingesta de datos meteorológicos** y la creación de la **Capa Bronce** de nuestro proyecto:\n",
    "\n",
    "1. **Lectura de datos crudos** provenientes de archivos del Servicio Meteorológico Nacional.\n",
    "2. **Estructuración inicial de datos**, manteniendo la información tal como llega del entorno real, sin limpieza ni transformación.\n",
    "3. **Organización en la estructura de carpetas** del proyecto, asegurando que los datos queden almacenados en la capa correspondiente para futuras etapas de procesamiento.\n",
    "\n",
    "Esta etapa constituye la **base del pipeline de datos**, preservando la trazabilidad y sirviendo como fuente de verdad para las capas posteriores (Plata y Oro)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
